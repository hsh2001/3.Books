# Introduction To Algorithms
### 지은이 : Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Clifford Stein
### 옮긴이 : 문병로, 심규석, 이충세
### 출판사 : The MIT Press, 한빛아카데미
### 읽은 날 : 2020.02.07 ~

### 목차

1. 기초

1)알고리즘의 역할

2)시작하기

3)함수의 증가

4)분할정복

5)확률적 분석과 랜덤화된 알고리즘

2. 정렬과 순서 통계량

6)힙 정렬

7)퀵 정렬

8)선형 시간 정렬

9)중앙값과 순서 통계량

3. 자료구조

10)기본 자료구조

11)해시 테이블

12)이진 검색 트리

13)레드블랙 트리

14)자료구조의 확장

4. 고급 설계 및 분석 기법

15)동적 프로그래밍

16)그리디 알고리즘

17)분할상환 분석

5. 고급 자료구조

18)B-트리

19)피보나치 힙

20)반 엠데 보아스 트리

21)서로 소 집합의 자료구조

6. 그래프 알고리즘

22)기본 그래프 알고리즘

23)최소 신장 트리

24)단일 출발지 최단 경로

25)모든 쌍의 최단 경로

26)최대 플로우

7. 알고리즘 분야의 중요한 토픽

27)멀티스레드 알고리즘

28)행렬의 연산

29)선형 계획법

30)다항식과 FFT

31)정수론 알고리즘

32)스트링 매칭

33)계산 기하학

34)NP-완비성

35)근사 알고리즘

8. 부록 : 수학적 기초

A)합

B)집합과 기타

C)계산과 통계

D)행렬

### Chapter 1. 알고리즘의 역할

1. 알고리즘은 간단히 말해 어떤 값이나 값의 집합을 입력으로 받아 또 다른 값이나 값의 집합을 출력하는 잘 정의된 계산 절차를 말한다. 따라서 알고리즘은 어떤 입력을 어떤 출력으로 변환하는 일련의 계산 과정이라고 할 수 있다.

2. 게다가 응용 프로그램 수준에서 알고리즘이 필요 없는 프로그램도 실제로는 알고리즘에 상당히 의존한다. 프로그램에서 빠른 하드웨어가 중요하다면 그 하드웨어 설계에 알고리즘이 중요하다. 그래픽 사용자 인터페이스가 중요하다면 역시 그 설계 단계에서 알고리즘이 중요한 역할을 한다. 네트워킹이 중요한 프로그램이라면 네트워크에서 경로를 찾는 문제는 전적으로 알고리즘에 달렸다. 또한 기계어 코드 외의 프로그래밍 언어로 만든 프로그램이라면, 이 프로그램은 컴파일러, 인터프리터, 어셈블러 등으로 만들어지며 모두 알고리즘에 상당히 의존한다. 결국 알고리즘은 현대 컴퓨터 분야에서 거의 모든 기술의 중심에 있다고 할 수 있다.

3. “알고리즘에 대한 지식과 기술을 얼마나 알차게 학습했느냐”가 숙련된 프로그래머와 초보자를 구분하는 기준이 될 수 있다. 알고리즘에 대한 별다른 지식 없이도 최신 컴퓨터 기술을 통해 어떤 일을 할 수 있을지 모른다. 하지만 알고리즘에 대한 훌륭한 배경 지식을 쌓으면 훨씬 더 많은 일을 할 수 있을 것이다.

### Chapter 2. 시작하기

4. INSERTION-SORT의 수행시간은 입력에 의해 결정된다. … 일반적으로 입력 크기가 커질수록 알고리즘의 수행시간이 증가하므로 수행시간을 입력 크기의 함수로 표현한다.

5. 병합 정렬은 분할정복 기법을 아주 잘 이용한다. 직관적으로 설명하면 다음과 같다.
- 분할 : 정렬할n개 원소의 배열을 n/2개씩 부분 수열 두 개로 분할한다.
- 정복 : 병합 정렬을 이용해 두 부분 배열을 재귀적으로 정렬한다.
- 결합 : 정렬된 두 개의 부분 배열을 병합해 정렬된 배열 하나로 만든다.

6. 병합 정렬 알고리즘에서 핵심 작업은 “결합”단계에서 정렬된 두 부분 수열을 병합하는 것이다. 병합을 하기 위해 보조 프로시저 MERGE(A, p, q, r)이 필요한데, 여기서 A는 배열이고 p, q, r은 인덱스로 p <= q < r을 만족한다. 프로시저 MERGE는 두 부분배열 A[p..q]와 A[q+1..r]이 정렬되어 있다고 가정하고 이를 병합해서 정렬된 배열 하나를 만드는데, 이것이 원래의 부분 배열 A[p..r]을 대체한다.

### Chapter 3. 함수의 증가

### Chapter 4. 분할정복

7. 부분 문제가 재귀적으로 풀 수 있을 만큼 충분히 클 때 재귀 대상이라고 한다. 부분 문제가 충분히 작아져 더 이상 재귀 호출을 할 수 없을 때 재귀가 “바닥을 쳤다”고 하고, 베이스 케이스까지 내려왔다고 이야기한다. 때로는 입력의 크기가 더 작은 완전히 동일한 부분 문제 외에 원래의 문제와 다른 부분 문제를 풀어야 할 때도 있다. 그런 부분 문제는 결합 단계의 일부로 간주한다.

8. 치환법이 점화식의 해가 맞는지에 대한 간결한 증명을 제공해 준다고 하더라도 좋은 추측을 해내기가 어려울 때가 있다. 2.3.2절의 병합 정렬의 점화식을 분석하면서 한 것 같이 재귀 트리를 그리는 것은 좋은 추측식을 고안해내기 위한 직접적인 방법이다. 재귀 트리(recursion tree)에서는 각 노드가 재귀 호출되는 하위 문제 하나의 비용을 나타낸다. 레벨당 비용의 집합을 얻기 위해 트리의 각 레벨마다 그 비용을 합한 후, 재귀의 모든 레벨에서의 총 비용을 결정하기 위해 모든 레벨당 비용을 합한다.

### Chapter 5. 확률적 분석과 랜덤화된 알고리즘

9. 확률적 분석은 문제를 분석할 때 확률을 사용하는 것이다. 확률적 분석은 주로 알고리즘의 수행시간을 분석하기 위해 사용한다. 때로는 HIRE-ASSISTANT 프로시저에서의 고용 비용처럼 다른 값을 분석하기 위해서도 쓰인다.
확률적 분석을 하기 위해서는 입력의 분포에 대한 정보를 이용하거나 그에 관한 가정을 해야 한다. 그리고 평균 수행시간을 계산하기 위해 알고리즘을 분석해야 한다. 그러한 기댓값은 모든 가능한 입력의 분포에 따라 결정된다. 그러므로 가능한 모든 입력에 대한 수행시간의 평균을 구해야 한다. 모든 입력에 대한 수행시간의 평균을 평균 수행시간이라 한다.

10. 랜덤화된 알고리즘
확률적 분석을 이용하기 위해서는 입력의 분포에 대해 어느 정도 알아야 한다. 많은 경우, 입력 분포에 대해 알 수 있는 것이 거의 없다. 설사 입력 분포에 대해 어느 정도 아는 경우에도 그러한 지식을 계산 모델로 만들기 어려울 수 있다. 그래서 확률과 무작위성을 통해 알고리즘의 일부가 랜덤하게 동작하도록 함으로써 알고리즘 설계와 분석을 위한 도구로 종종 사용하게 된다.

### Chapter 6. 힙 정렬

11. 병합 정렬처럼(삽입 정렬과는 다르게) 힙 정렬의 수행시간도 O(nlgn)이다. 그리고 삽입 정렬처럼(병합 정렬과는 다르게) 힙 정렬은 내부 정렬이다. 즉, 정렬할 때 입력 배열에서 상수 개의 원소를 초과해서 배열 밖에 저장하는 일은 없다. 따라서 힙 정렬은 이미 논의한 두 정렬 알고리즘의 장점을 혼합한 것이다.

### Chapter 7. 퀵 정렬

12. 퀵 정렬은 원소 수가 n개인 입력 배열을 최악의 경우 O(n^2)에 정렬하는 알고리즘이다. 퀵 정렬은 최악의 경우에는 수행시간이 느리지만 평균 수행시간이 O(nlgn)으로 매우 효율적이고 O(nlgn) 표현에 숨겨진 상수 인자도 매우 작다. 또한 내부 정렬이라는 장점도 있고 가상 메모리 환경에서도 잘 동작해 일반적으로 실제 문제에서 가장 유용한 정렬 방법이다.

13. 퀵 정렬의 성능
퀵 정렬의 수행시간은 분할 후 양쪽 구역의 크기가 비슷한지 그렇지 않은지에 따라 달라지고, 분할의 균형도는 분할할 때마다 어떤 기준 원소를 사용하는지에 달려 있다. 분할이 균등하게 되면 퀵 정렬은 (점근적으로) 병합 정렬처럼 빠르게 동작한다. 그러나 균등하지 않다면 삽입 정렬처럼 느리게 동작한다. 

### Chapter 8. 선형 시간 정렬

14. 어떤 비교 정렬 알고리즘이라도 원소 n개를 정렬할 때 최악의 경우 비교 Ω(nlgn)번 해야 함을 증명한다. 따라서 병합 정렬과 힙 정렬은 점근적으로 최적이고, 이들에 비해 상수배보다 빠른 비교 정렬은 존재하지 않는다.

### Chapter 9. 중앙값과 순서 통계량

### Chapter 10. 기본 자료구조

### Chapter 11. 해시 테이블
15. 응용 프로그램들은 종종 Insert, Search, Delete와 같은 사전적 작업을 지원하는 동적 집합을 필요로 한다. 예를 들어, 컴파일러는 컴퓨터 언어의 식별자(identifier)에 해당ㅇ하는 임의의 문자열이 원소의 키값이 되는 심볼 테이블을 관리한다. 해시 테이블은 사전을 구현하는 효율적인 자료 구조다. 이론적으로는 해시 테이블에서 원소를 찾는 것이 연결 리스트에서 원소를 찾는 것(최악의 경우 O(n)의 수행시간을 가진다)만큼 오래 걸릴 수 있지만 실제로 해싱은 성능이 탁월하다. 합리적인 가정 하에서 해시 테이블에서 원소를 찾는 데 걸리는 평균 수행시간은 O(1)이다.

16. 직접 주소화 병합에서 키 k를 갖는 원소가 위치 k에 저장된다. 그리고 해싱을 이용한 방법에서는 키 k를 갖는 원소는 위치 h(k)에 저장된다. 즉, 키로부터 저장될 위치를 계산하기 위해 해시 함수 h를 사용한다. 여기서 h는 키들의 전체 집합 U를 해시 테이블 T[0..m - 1]의 각 위치에 대응시킨다.

H : U → {0,1,…,m-1}

이때 해시 테이블의 크기 m은 일반적으로 |U|보다 훨씬 작다. “키 k를 갖는 원소가 위치 h(k)에 해시된다”고 말하고 “h(k)는 키 k의 해시 값이다”라고 한다. 그림 11.2는 기본 아이디어를 설명하고 있다. 해시 함수는 배열의 인덱스 범위를 줄이게 되어 배열의 크기를 줄이게 된다. 배열은 |U|의 크기 대신 크기 m을 가진다.

17. 무엇이 좋은 해시 함수를 만드는가?
좋은 해시 함수는 다른 키가 해시된 위치와는 상관없이 각 키가 m개의 자리 중 하나에 같은 확률로 해시된다는 단순 균등 해싱의 가종을 만족한다. 불행히도 키가 추출되는 확률 분포를 알기 힘들기 때문에 일반적으로 이 조건을 검사할 방법이 없다. 게다가 키가 독립적으로 추출되지 않을 수도 있다.

18. 좋은 해시 함수는 이와 같은 유사한 것이 동일한 자리에 해시되는 확률을 최소화해야 한다. 좋은 방법은 자료에 존재하는 어떠한 패턴에도 독립적이도록 해시값을 계산한다. 예를 들어, “나누기 방법”은 키를 특정한 소수로 나눈 나머지를 해시값으로 사용한다. 이 방법은 키들의 분포에 나타나는 어떠한 경향과도 관련되지 않도록 소수를 선택한다고 가정하면 흔히 좋은 결과를 가져온다.

19. 개방 주소화 방법(open-addressing)에서는 모든 원소가 해시 테이블 그 자체에 저장된다. 즉, 테이블의 각 저장 위치는 동적 집합의 원소나 NIL을 포함한다. 원소를 검색할 때 찾고자 하는 원소를 발견하거나 그 원소가 테이블에 존재하지 않는다는 것이 명확할 때까지 체계적인 조사가 이루어진다. 체이닝과 달리 테이블 외부에 저장된 리스트나 원소는 없다. 그러므로 개방 주소화 방법에서는 해시 테이블이 “꽉 차서” 더 이상 삽입이 가능하지 않을 수도 있다. 그러므로 적재율은 절대 1을 넘을 수 없다.
물론 해시 테이블 내부에 사용되지 않은 공간을 이용해서 체이닝을 위한 연결 리스트를 저장할 수 있다. 그러나 개방 주소화 방법의 장점은 포인터를 전혀 사용하지 않는다는 것이다. 포인터를 따라가는 대신 조사될 위치의 순서를 계산한다. 포인터를 저장하지 않음으로써 얻어진 추가 메모리는 해시 테이블의 저장 공간 확장에 이용된다. 이것은 결과적으로 충돌을 줄이고 빠른 접근을 가능하게 한다.

### Chapter 12. 이진 검색 트리

20. 이진 검색 트리에서 키들은 항상 다음의 이진 검색 트리 특성(binary-search-tree property)을 만족하도록 저장된다.

x를 이진 검색 트리의 한 노드라고 하자. Y가 x의 왼쪽 서브 트리의 한 노드면 y.key <= x.key를 만족한다. 그리고 y가 x의 오른쪽 서브 트리의 한 노드면 y.key >= x.key를 만족한다.

### Chapter 13. 레드블랙 트리

21. 높이가 h인 이진 검색 트리에서 Search, Predecessor, Successor, Minimum, Maximum, Insert, Delete와 같은 동적 집합 연산이 O(h) 시간에 수행될 수 있음을 보였다. 따라서 검색 트리의 높이가 작은 경우 이런 집합 연산을 빠르게 수행할 수 있다. 그러나 높이가 클 경우 연산의 실행 속도는 연결 리스트와 비슷한 정도에 불과하다. 레드블랙 트리는 트리가 “균형을 이루도록” 고안된 검색 트리 구조 중 하나로, 기본적인 동적 집합 연산을 최악의 경우에도 O(lgn) 시간에 수행하도록 보장한다.

22. 레드블랙 트리(red-black tree)는 이진 검색 트리로서 각 노드당 한 비트의 추가 기억 공간을 가진다. 이 비트는 노드의 색깔을 나타내는데, 적색이나 혹색이 될 수 있다. 레드블랙 트리는 루트에서 리프까지의 경로에 나타나는 노드의 색깔을 제한함으로써 그러한 경로 중 어떠한 것도 다른 것보다 두 배 이상 길지 않음을 보장 하게 되는데, 이로써 트리는 근사적으로 균형을 이룬 트리가 된다.

23. 다음 레드블랙 특성을 만족하는 이진 검색 트리를 레드블랙 트리라고 한다.
1.모든 노드는 적색이거나 흑색이다.
2.루트는 흑색이다.
3.모든 리프(NIL)는 흑색이다.
4.노드가 적색이면 그 노드의 자식은 모두 흑색이다.
5.각 노드로부터 그 노드의 자손인 리프로 가는 경로들은 모두 같은 수의 흑색 노드를 포함한다.

### Chapter 14. 자료구조의 확장

24. 교재에 나오는 양방향 연결 리스트, 해시 테이블, 이진 검색 트리와 같은 기본적인 자료구조를 이용하는 것만으로 충분한 상황도 있지만 새로운 조건이 필요한 상황도 있다. 그러나 완전히 새로운 형태의 자료구조가 필요한 경우는 드물다. 그래서 대부분 기본 자료구조에 추가 정보를 저장해 기존 자료구조를 확장하기만 하면 된다. 이렇게 확장한 자료구조를 이용해 원하는 용도의 새로운 연산을 프로그래밍할 수 있다. 그렇지만 자료구조의 확장이 항상 간단하지는 않다. 추가된 정보가 그 자료구조에서 수행되는 일반적인 연산에 의하여 갱신되고 유지되어야 하기 때문이다.

25. 자료구조의 확장은 다음 네 단계로 나눌 수 있다.
1.자료구조를 선택한다.
2.자료구조에서 유지할 추가 정보를 결정한다.
3.자료구조의 기본 연산에 대해 추가 정보가 유지될 수 있는지를 확인한다.
4.새로운 연산을 개발한다.

### Chapter 15. 동적 프로그래밍

26. 동적 프로그래밍은 일반적으로 최적해(optimal solution)에 도달하기 위해 일련의 선택이 이루어지는 최적화 문제에 적용된다. 각각의 선택을 하는 과정에서 종종 같은 형태의 부분 문제가 생긴다. 동적 프로그래밍은 어떤 부분 문제가 둘 이상의 부분적인 선택 집합에서 발생하는 경우에 효과적이다. 이 기법의 중요한 특징은 부분 문제의 해가 다시 나타나는 경우를 대비해 그 해를 저장해두는 것이다. 15장에서는 이 간단한 아이디어가 수행시간이 지수 함수에 비례하는(exponential-time) 알고리즘에서 수행시간이 다항 함수에 비례하는(polynomial-time) 알고리즘으로 바꾸는 방법을 보여준다.

27. 그리디 알고리즘도 동적 프로그래밍 알고리즘과 마찬가지로 일반적으로 최적해에 도달하기 위해 일련의 선택이 이루어지는 최적화 문제에 적용된다. 그리디 알고리즘의 아이디어는 지역적으로(locally) 각각의 선택을 한다는 것이다.

28. 그리디 알고리즘은 이런 많은 문제에서 동적 프로그래밍 알고리즘보다 최적해를 더 빨리 찾아낸다. 그러나 그리디 알고리즘이 효과적인지 확인하는 일은 쉽지 않을 수도 있다. 16장에서는 그리디 알고리즘이 최적해를 참음을 보이는 수학적 기초를 제공하는 매트로이드 이론(matroid theory)을 다룬다.

29. 일련의 비슷한 연산을 수행하는 어떤 알고리즘을 분석하기 위해 분할상환 분석을 이용한다. 이 분석 방법은 개별 연산에 대한 비용의 상한값을 이용해 전체 비용의 상한을 계산하는 대신, 전체 연산에 대한 실제 상한값을 제공한다. 일부 연산의 비용은 매우 비싸고 대다수의 연산의 비용은 매우 싼 경우에 이런 접근 방식의 장점을 찾을 수 있다. 다시 말해, 많은 연산들은 최악의 경우의 시간보다 적은 시간에 아주 잘 동작한다. 그러나 분할상환 분석이 분석 도구인 것만은 아니다. 분할상환 분석이 알고리즘의 설계와 수행시간 분석에 밀접하게 연관되어 있는 경우도 종종 있으므로 알고리즘을 설계하는 하나의 방법이라고도 할 수 있다.

30. 동적 프로그래밍(dynamic programming)은 분할정복 기법과 같이 부분 문제의 해를 결합해 문제를 해결한다(여기서 “프로그래밍”은 컴퓨터 코드를 쓰는 것이 아니라 테이블을 이용한 방법을 일컫는다). 2장에서 보았듯이, 분할정복 알고리즘은 문제를 서로 겹치지 않는(disjoint) 부분 문제로 분할하고, 해당 부분 문제를 재귀적으로 해결한 후, 해결 결과를 결합하여 원래의 문제를 해결한다. 반면, 동적 프로그래밍은 부분 문제가 서로 중복될 때, 즉 부분 문제가 다시 자신의 부분 문제를 공유할 때 적용할 수 있다. 이 경우, 분할정복 알고리즘은 공유되는 부분 문제를 반복적으로 해결하여 일을 필요 이상으로 더 많이 하게 된다. 동적 프로그래밍 알고리즘을 이용하면 모든 부분 문제를 한 번만 풀어 그 해를 테이블에 저장함으로써 각 부분 문제를 풀 때마다 다시 계산하는 일을 피할 수 있다. 

31. 일반적으로 최적화 문제(optimization problem)에 동적 프로그래밍을 적용한다. 이런 문제는 다양한 해를 가질 수 있다. 각 해는 값을 가져 이 중 최적(최소 또는 최대)의 값인 해를 찾기를 원한다. 이런 해를 그 문제에 대한 유일한 최적해라 하지 않고 한 개의 최적해라 한다. 최적의 값을 가지는 해가 여러 개 존재할 수 잇기 때문이다. 동적 프로그래밍 알고리즘을 개발할 때는 다음 4단계를 따른다.
1.최적해의 구조의 특징을 찾는다.
2.최적해의 값을 재귀적으로 정의한다.
3.최적해의 값을 일반적으로 상향식(bottom-up) 방법으로 계산한다.
4.계산된 정보들로부터 최적해를 구성한다.

32. 전체적인 최적해는 두 부분 문제의 각각에 대해 수익을 최대화하는 해를 이용한다. 막대 자르기 문제는 최적 부분 구조(optimal substructure)를 가졌다고 한다. 그러므로 하나의 문제에 대한 최적해는 각각을 독립적으로 풀 수 있는 연관된 부분 문제들의 최적해를 이용한다.

33. 동적 프로그래밍 방법은 다음과 같이 동작한다. 초보적인 재귀해는 같은 부분 문제를 반복하여 풀어 비효율적임을 관찰했으므로, 각 부분 문제를 단 g나 번만 풀고 그 해를 저장하도록 처리한다. 그러면 이 부분 문제의 해를 나중에 다시 구할 때 다시 계산하지 않고 저장된 값을 참조만 한다. 그래서 동적 프로그래밍은 계산 시간을 절약하기 위해 부가적인 메모리를 더 사용한다. 이는 시간-메모리 트레이드-오프(time-memory trade-off)의 한 예로 작용한다. 지수 함수에 비례하는 시간의 해는 다항식에 비례하는 시간으로 변환될 수도 있듯이 극적으로 시간을 절약할 수 있다. 관련된 각각의 다른 부분 문제의 개수가 입력 크기에 대해 다항식에 비례하고 각 부분 문제를 다항식에 비례하는 시간에 풀 수 있다면, 동적 프로그래밍 방법은 다항식에 비례하는 시간에 수행된다.

34. 동적 프로그래밍 방법을 구현하는 데 보통 두 가지 방법이 존재한다. 막대 자르기 예를 통해 두 가지 방법을 모두 설명하겠다.

35. 첫 번째 방법은 메모하기를 이용한 하향식이다. 이 방법에서 프로시저를 자연스럽게 재귀적으로 쓰지만 각각의 부분 문제의 결과를 보통 배열이나 해시 테이블에 저장해놓도록 수정한다. 그리고 이 프로시저는 이 부분 문제를 이전에 풀었는지 알아보기 위해 확인을 한다. 이전에 풀었다면 이 레벨에서 이후에 계산하는 것을 절약하면서 그 저장된 결과를 리턴한다. 그리고 이전에 풀지 않았다면 이 프로시저는 통상적인 방법으로 값을 계산한다. 그러면 이 재귀 프로시저가 메모되었다라고 말한다. 이 프로시저는 이전에 이미 계산된 결과를 “기억한다.”

36. 두 번째 방법은 상향식 방법이다. 이 방법은 부분 문제의 “크기”라는 자연스러운 개념을 따르는데, 특정 부분 문제를 푸는 것이 “더 작은” 부분 문제를 푸는 것에만 의존한다. 부분 문제를 크기별로 정렬한 후 가장 작은 것을 첫 번째로 하여 크기 순으로 푼다. 특정 부분 문제를 풀 때는 그 해에 영향을 미치는 더 작은 부분 문제를 모두 풀어 그 해를 저장해놓는다. 그러므로 각 부분 문제를 한 번만 풀고 새로 등장하는 부분 문제에 필요한 모든 부분 문제는 이미 다 풀어놓은 상태가 된다.

37. 이런 두 가지 방법은 하향식 방법이 실제로 모든 부분 문제를 조사하려고 재귀적으로 호출하지 않는 경우를 제외하고는, 똑 같은 점근적인 수행시간을 가진 알고리즘을 만든다. 상향식 방법은 프로시저 호출에 대한 오버헤드가 더 작아 종종 훨씬 더 나은 상수 비율(constant factor)을 가진다.

38. 동적 프로그래밍을 이용해 최적화 문제를 풀기 위해서 맨 먼저 할 일은 최적해의 구조의 특징을 살펴보는 것이다. 문제의 최적해가 그 안에 부분 문제의 최적해를 포함하고 있을 때 그 문제는 최적 부분 구조를 가짐을 기억하자. 어떤 문제가 최적 부분 구조(optimal substructure)를 가진다는 것은 동적 프로그래밍이 적용될 수 있는 좋은 단서를 제공한다.

39. 16장에서는 동적 프로그래밍과 여러 가지 면에서 유사한 “그리디 알고리즘”에 대해 살펴볼 것이다. 특히 그리디 알고리즘이 적용되는 문제도 최적 부분 구조를 가진다는 점에서 동적 프로그래밍과 유사하다. 그리디 알고리즘과 동적 프로그래밍 사이의 가장 두드러지는 차이는 동적 프로그래밍은 부분 문제들의 최적해를 먼저 구한 후 선택을 하는 반면, 그리디 알고리즘은 가능한 관련된 더 작은 부분 문제를 모두 풀려고 하지 않고 “그리디” 선택(그 순간에 가장 좋아 보이는 선택)을 한 다음에 그 결과로 얻어진 부분 문제만을 푼다. 놀랍게도 어떤 경우에는 이런 전략이 아무 문제 없이 적용된다!

### Chapter 16. 그리디 알고리즘

40. 최적화 문제에서 동적 프로그래밍을 사용하면 가장 좋은 선택을 결정하기 위해 지나치게 많은 일을 하게 된다. 오히려 더 간단하고 효율적인 알고리즘만으로도 충분한 경우가 많다. 그리디 알고리즘(greedy algorithm)은 항상 각 단계에 있어서 가장 좋을 거라 생각되는 선택을 한다. 다시 말해 이 선택이 전체적으로 최적해로 안내하게 될 거라는 바람을 가지고 부분적으로 최적인 선택을 한다.

### Chapter 17. 분할상환 분석

### Chapter 18. B-트리

### Chapter 19. 피보나치 힙

### Chapter 20. 반 엠데 보아스 트리

### Chapter 21. 서로 소 집합의 자료구조

### Chapter 22. 기본 그래프 알고리즘

41. 너비 우선 검색(BFS)은 가장 단순한 그래프 검색 알고리즘 중 하나로, 중요한 그래프 알고리즘들의 원형(archetype)이다. 프림(Prim)의 최소 신장 트리 알고리즘과 다익스트라(Dijkstra)의 단일 출발점 최단 경로 알고리즘은 너비 우선 검색에서와 비슷한 아이디어를 사용한다.

42. BFS 프로시저를 수행하는 데 걸리는 총 시간은 O(V+E)다. 그러므로 너비 우선 검색은 그래프 G의 인접 리스트 표현의 크기에 선형적으로 비례하는 시간이 걸린다.

43. DFS의 수행시간은 O(V+E)다.

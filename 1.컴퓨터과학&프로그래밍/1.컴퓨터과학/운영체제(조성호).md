# 운영체제
### 지은이 : 조성호
### 출판사 : 한빛아카데미
### 읽은 날 : 2020.02.22 ~

<목차>
# Part1. 운영체제와 컴퓨터
### Chapter 1. 운영체제의 개요
1. 운영체제 소개
2. 운영체제의 역사
3. 운영체제의 구조
4. 운영체제의 종류와 역사

### Chapter 2. 컴퓨터 구조와 성능 향상
1. 컴퓨터의 기본 구성
2. CPU와 메모리
3. 컴퓨터 성능 향상 기술
- 버퍼
- 캐시
- 저장장치의 개층 구조
- 인터럽트
4. 병렬 처리
5. 무어의 법칙과 암달의 법칙


# Part2. 프로세스 관리
### Chapter 3. 프로세스와 스레드
1. 프로세스 개요
2. 프로세스 제어 블록과 문맥 교환
3. 프로세스의 연산
4. 스레드
5. 동적 할당 영역과 시스템 호출

### Chapter 4. CPU 스케줄링
1. 스케줄링의 개요
2. 스케줄링 시 고려 사항
3. 다중 큐
4. 스케줄링 알고리즘
5. 인터럽트 처리

### Chapter 5. 프로세스 동기화
1. 프로세스 간 통신
2. 공유 자원과 임계구역
3. 임계구역 해결 방법
4. 파일, 파이프, 소켓 프로그래밍

### Chapter 6. 교착 상태
1. 교착 상태의 개요
2. 교착 상태 필요조건
3. 교착 상태 해결 방법
4. 다중 자원과 교착 상태 검출


#Part3. 메모리 관리
### Chapter 7. 물리 메모리 관리
1. 메모리 관리의 개요
2. 메모리 주소
3. 단일 프로그래밍 환경에서의 메모리 할당
4. 다중 프로그래밍 환경에서의 메모리 할당
5. 컴파일과 메모리 관리

### Chapter 8. 가상 메모리 기초
1. 가상 메모리 개요
2. 페이징 기법
3. 세그먼테이션 기법
4. 세그먼테이션-페이징 혼용 기법
5. 캐시 매핑 기법

### Chapter 9. 가상 메모리 관리
1. 요구 페이징
2. 페이지 교체 알고리즘
3. 스레싱과 프레임 할당
4. 프레임 관련 이슈


# Part4. 저장장치 관리
### Chapter 10. 입출력 시스템과 저장장치
1. 입출력 시스템
2. 디스크 장치
3. 디스크 스케줄링
4. RAID
5. 하드웨어의 규격과 발전

### Chapter 11. 파일 시스템
1. 파일과 파일 시스템
2. 디렉터리의 구조
3. 디스크 파일 할당
4. 유닉스 파일의 특징

# Part5. 분산 시스템
### Chapter 12. 네트워크와 분산 시스템
1. 네트워크와 인터넷
2. 분산 시스템
3. 분산 시스템의 고가용성

-------------------------------------------
# Part1. 운영체제와 컴퓨터
# Chapter 1. 운영체제의 개요
### 1. 운영체제 소개
1. 펌웨어  
운영체제는 우리가 사용하는 각종 소프트웨어 중 하나이다. 게임이나 문서 편집기 같은 소프트웨어가 특정 목적을 위해 존재한다면, 운영체제는 컴퓨터에 있는 하드웨어(자원)를 조정하고 관리하기 위해 존재한다. 그런데 운영체제는 하드웨어를 조정하고 관리하는 역할을 하므로 하드웨어의 도움 없이 작동하기가 어렵기 때문에 운영체제를 소프트웨어와 하드웨어로 결합한 형태인 펌웨어(firmware)라고 부르기도 한다.

2. 운영체제는 하드웨어 인터페이스가 자동으로 설치되게 함으로써 하드웨어의 종류에 상관없이 사용할 수 있게 해준다.

### 2. 운영체제의 역사
3. 천공카드 리더로 하나의 작업을 읽어들여 실행하고 결과를 출력한 후 다음 작업을 읽어들여 실행했다. 이러한 시스템에서는 작업에 필요한 프로그램과 데이터를 동시에 입력해야 작업이 가능하다. 지금의 프로그래밍 환경과 달리 모든 작업을 한꺼번에 처리해야 하고 프로그램 실행 중간에 사용자가 데이터를 입력하거나 수정하는 것이 불가능한데, 이러한 시스템을 일괄 작업 시스템(batch job system)또는 일괄 처리 시스템(batch processing system)이라고 부른다.

4. 이처럼 여러 작업을 조금씩 처리하여 작업이 동시에 이루어지는 것처럼 보이게 하는 것을 시분할 시스템(time sharing system)이라고 한다. 다중 작업(multitasking)시스템이라고도 불리는 시분할 시스템에서는 CPU 사용 시간을 잘게 나뉜 시간 한 조각을 타임 슬라이스(time slice)또는 타임 퀀텀(time quantum)이라고 한다. 오늘날의 컴퓨터에는 대부분 시분할 시스템이 사용된다.

### 3. 운영체제의 구조
5. 시스템 호출(system call)  
시스템 호출은 커널이 자신을 보호하기 위해 만든 인터페이스이다. 커널은 사용자나 응용 프로그램으로부터 컴퓨터 자원을 보호하기 위해 자원에 직접 접근하는 것을 차단한다. 따라서 자원을 이용하려면 시스템 호출이라는 인터페이스를 이용하여 접근해야 한다.

6. 시스템 호출에 관한 내용을 정리하면 다음과 같다.
- 시스템 호출은 커널이 제공하는 시스템 자원의 사용과 연관된 함수이다.
- 응용 프로그램이 하드웨어 자원에 접근하거나 운영체제가 제공하는 서비스를 이용하려 할 때는 시스템 호출을 사용해야 한다.
- 운영체제는 커널이 제공하는 서비스를 시스템 호출로 제한하고 다른 방법으로 커널에 들어오지 못하게 막음으로써 컴퓨터 자원을 보호한다.
- 시스템 호출은 커널이 제공하는 서비스를 이용하기 위한 인터페이스이며, 사용자가 자발적으로 커널 영역에 진입할 수 있는 유일한 수단이다.

7. 시스템 호출 부분을 보면 커널 앞부분 전체를 감싸고 있는데, 이는 시스템 호출을 거치지 않고 커널에 진입할 수 없다는 의미이다. 반면에 드라이버는 커널 전체를 감싸고 있지 않다. 이는 커널이 제공하는 드라이버도 있고 하드웨어 제작자가 제공하는 드라이버도 있다는 뜻으로, 하드웨어는 커널과 직접 연결되기도 하고 하드웨어 제작자가 제공하는 드라이버를 통해 연결되기도 한다.

8. 커널이 하는 일  
- 프로세스 관리 : 프로세스에 CPU를 배분하고 작업에 필요한 제반 환경을 제공한다.
- 메모리 관리 : 프로세스에 작업 공간을 배치하고 실제 메모리보다 큰 가상공간을 제공한다.
- 파일 시스템 관리 : 데이터를 저장하고 접근할 수 있는 인터페이스를 제공한다.
- 입출력 관리 : 필요한 입력과 출력 서비스를 제공한다.
- 프로세스 간 통신 관리 : 공동 작업을 위한 각 프로세스 간 통신 환경을 지원한다.

9. 이런 호환성 문제를 해결한 언어가 바로 자바이다. 자바로 프로그래밍을 하면 대부분의 운영체제에서 작동하기 때문에 코드를 수정할 필요가 없다. 자바가 작동하는 원리는 매우 간단하다. 운영체제 위에 가상머신을 만들고 그 위에서 응용 프로그램이 작동하게 하는 것이다.

10. 가상머신의 개념은 다양한 곳에서 사용된다. 예를 들어 윈도우 운영체제 환경에서 유닉스를 사용하고 싶다고 가정해보자. 이 경우 윈도우 운영체제와 유닉스 운영체제를 같이 설치하고 부팅할 때 어떤 운영체제를 사용할지 선택해야 한다. 그러나 대부분의 작업을 윈도우에서 하고 유닉스는 가끔 사용한다면 하나의 컴퓨터에 두 가지 운영체제를 설치하기가 부담스러운데, 이럴 때는 윈도우 운영체제에 유닉스 가상머신을 설치하여 사용하면 된다. 가상머신을 사용하면 호환성이 높아지지만 응용 프로그램이 가상머신을 통해서만 작동하기 때문에 느려진다는 단점도 있다.

11. 커널의 종류
- 단일형 구조 커널 : 커널의 핵심 기능을 구현하는 모듈들이 구분 없이 하나로 구성되어 있다.
- 계층형 구조 커널 : 비슷한 기능을 가진 모듈을 묶어서 하나의 계층으로 만들고 계층 간의 통신을 통해 운영체제를 구현하는 방식이다.
- 마이크로 구조 커널 : 운영체제가 프로세스 관리, 메모리 관리, 프로세스 간 통신 관리 등 가장 기본적인 기능만 제공한다.

### 4. 운영체제의 종류와 역사

# Chapter 2. 컴퓨터 구조와 성능 향상
### 1. 컴퓨터의 기본 구성
12. 폰노이만 구조에서 가장 중요한 특징은, ‘모든 프로그램은 메모리에 올라와야 실행할 수 있다’는 것이다.

13. 클록(clock)  
클록은 CPU 속돵 관련된 단위이다. 다양한 악기로 조합된 오케스트라는 박자가 맞아야 제대로 곡을 연주할 수 있듯이 CPU도 작업을 할 때 일정한 박자가 있는데, 이 박자를 만들어내는 것이 클록이다. 클록이 일정한 간격으로 틱(tick)을 만들면 거기에 맞추어 CPU안의 모든 구성 부품이 작업을 한다. 틱은 펄스(pulse) 또는 클록틱(clock tick)이라고도 부른다. 버스에는 여러 개의 부품이 연결되어 있는데, 메인보드의 클록이 틱을 보낼 때마다 데이터를 보내거나 받는다.

14. 헤르츠(Hz)  
헤르츠는 클록틱이 발생하는 속도를 나타내는 단위이다. 1초에 클록틱이 몇 번 발생하는지를 나타내는데, 1초에 클록틱이 한 번이면 1Hz, 1000번이면 1kHz이다.

15. 시스템 버스(system bus)와 CPU 내부 버스  
시스템 버스는 메모리와 주변장치를 연결하는 버스로 FSB(Front-Side Bus), 즉 전면 버스라고 한다. 1,333MHz의 시스템 버스를 가진 메인보드에는 같은 속도를 가진 부품이 연결되고 메모리도 1,333MHz의 속도로 작동한다.

16. CPU 내부 버스는 CPU 내부에 있는 장치를 연결하는 버스로 BSB(Back-Side Bus), 즉 후면 버스라고 한다. CPU 내부 버스의 속도는 CPU 클록과 같아서 시스템 버스보다 훨씬 빠르다.

### 2. CPU와 메모리
17. CPU는 0과 1의 2진수로 이루어진 기계어(machine code)만 인식한다. 따라서 위 코드를 실행하려면 컴파일러를 이용하여 기계어로 바꾸어야 한다. 여기서는 사람이 이해하기 어려운 기계어 대신 어셈블리어로 작성한 코드를 살펴보자. 어셈블리어는 기계어를 사람이 이해하기 쉬운 기호와 일대일로 대응시켜 기호화한 언어이다.

18. 사용자 가시 레지스터  
- 데이터 레지스터(DR) : CPU가 명령어를 처리하는 데 필요한 일반 데이터를 임시로 저장하는 범용 레지스터이다.
- 주소 레지스터(AR) : 데이터 또는 명령어가 저장된 메모리 주소를 저장한다.

19. 사용자 불가시 레지스터  
- 프로그램 카운터(PC) : 다음에 실행할 명령어의 위치 정보(코드의 행 번호, 메모리 주소)를 저장한다.
- 명령어 레지스터(IR) : 현재 실행 중인 명령어를 저장한다.
- 메모리 주소 레지스터(MAR) : 메모리 관리자가 접근해야 할 메모리의 주소를 저장한다.
- 메모리 버퍼 레지스터(MBR) : 메모리 관리자가 메모리에서 가져온 데이터를 임시로 저장한다.
- 프로그램 상태 레지스터(PSR) : 연산 결과(양수, 음수 등)를 저장한다.

20. 제어 버스(control bus)  
제어 버스에서는 다음에 어떤 작업을 할지 지시하는 제어 신호가 오고 간다. … 제어 버스의 신호는 CPU, 메모리, 주변장치와 양방향으로 오고 간다.

21. 주소 버스(address bus)  
주소 버스에서는 메모리의 데이터를 읽거나 쓸 때 어느 위치에서 작업할 것인지를 알려주는 위치 정보(주소)가 오고 간다. … 주소 버스는 메모리 주소 레지스터와 연결되어 있으며 단방향이다. CPU에서 메모리나 주변장치로 나가는 주소 정보는 있지만 주소 버스를 통해 CPU로 전달되는 정보는 없다.

22. 데이터 버스(data bus)  
제어 버스가 다음에 어떤 작업을 할지 신호를 보내고 주소 버스가 위치 정보를 전달하면 데이터가 데이터 버스에 실려 목적지까지 이동한다. 데이터 버슨느 메모리 버퍼 레지스터와 연결되어 있으며 양방향이다.

23. 버스의 대역폭(bandwidth)은 한 번에 전달할 수 있는 데이터의 최대 크기를 말한다. … 흔히 32bit CPU, 64bit CPU라고 하는데 여기서 32bit, 64bit는 CPU가 한 번에 처리할 수 있는 데이터의 최대 크기이다. … 참고로 CPU가 한 번에 처리할 수 있는 데이터의 최대 크기를 워드(word)라고 하며, 버스의 대역폭과 메모리에 한 번에 저장되는 단위도 워드이다. 32bit CPU에서 1워드는 32bit이다.

24. 휘발성 메모리(volatility memory)  
휘발성 메모리에는 DRAM(Dynamic RAM, 동적 램)과 SRAM(Static RAM, 정적 램)이 있다. DRAM은 저장된 0과 1의 데이터가 일정 시간이 지나면 사라지므로 일정 시간마다 다시 재생시켜야 한다. DRAM의 ‘Dynamic’은 시간이 지나면 데이터가 사라지기 때문에 재생이 필요하다는 의미이다. SRAM은 전력이 공급되는 동안에는 데이터를 보관할 수 있어 재생할 필요가 없다. 따라서 속도는 빠르지만 가격이 비싸다. 일반적으로 메인메모리에는 DRAM을 사용하고, 캐시 같은 고속 메모리에는 SRAM을 사용한다.

25. 위 그림에서 B 작업의 메모리 시작 주소 140은 경계 레지스터에, B 작업의 크기 40은 한계 레지스터에 저장된다. B 작업이 데이터를 읽거나 쓸 때마다 CPU는 해당 작업이 경계 레지스터와 한계레지스터의 주소값 안에서 이루어지는지 검사한다. 만약 두 레지스터의 값을 벗어난다면 메모리 오류와 관련된 인터럽트가 발생한다. 인터럽트가 발생하면 모든 작업이 중단되고 CPU는 운영체제를 깨워서 인터럽트를 처리하도록 시킨다. 이처럼 모든 메모리 영역은 하드웨어와 운영체제의 협업에 의해 보호받는다.

26. 부팅(booting)  
컴퓨터를 켰을 때 운영체제를 메모리에 올리는 과정을 부팅이라고 한다.

27. 부트스트랩 코드는 운영체제를 메모리로 가져와 실행하는 역할을 하는 작은 프로그램이다.

### 3. 컴퓨터 성능 향상 기술
28. 현대 컴퓨터 구조의 가장 큰 문제는 CPU와 메모리, 주변장치의 작업 속도가 다르다는 것이다. 앞에서 살펴보았듯이 메인보드 내 메모리와 주변장치는 시스템 버스(FSB)로 연결되어 있고, CPU 내 레지스터, 산술논리 연산장치, 제어장치는 CPU 내부 버스(BSB)로 연결되어 있다. 따라서 메모리의 속도는 시스템 버스의 속도와 같고 CPU의 속도는 CPU 내부 버스의 속도와 같은데, CPU 내부 버스의 속도가 시스템 버스의 속도보다 빠르기 때문에 메모리를 비롯한 주변장치의 속도가 CPU의 속도를 따라가지 못한다. CPU에 비하면 메모리가 느린 것은 물론이고, 프로그램과 데이터를 보관하는 하드디스크의 속도는 더욱 느리다.

29. 버퍼(buffer)  
버퍼는 속도에 차이가 있는 두 장치 사이에서 그 차이를 완화하는 역할을 한다. … 일정량의 데이터를 모아 옮김으로써 속도 차이를 완화하는 장치가 버퍼이다.

30. 하드디스크에는 메모리 버퍼가 있다. 표2-2의 하드디스크 사양은 1TB, 7200rpm, 32MB인데, 이는 하드디스크의 용량이 1TB, 디스크의 회전 속도가 7500rpm, 버퍼의 용량이 32MB라는 의미이다. 같은 사양의 하드디스크라면 버퍼의 용량이 큰 것이 더 빠르다.

31. 스풀러는 일종의 버퍼이지만 기존의 버퍼와 다른 점이 있다. 버퍼의 경우 어떤 프로그램이 사용하는 데이터든 버퍼가 차면 이동이 시작된다. 다시 말해 프로그램들이 버퍼를 공유한다. 반면에 스풀러는 한 인쇄물이 완료될 때까지 다른 인쇄물이 끼어들 수 없으므로 프로그램 간에 배타적이다.

32. 캐시(cache)  
캐시는 메모리와 CPU 간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해두는 임시 장소이다. 캐시는 필요한 데이터를 모아 한꺼번에 전달하는 버퍼의 일종으로 CPU가 앞으로 사용할 것으로 예상되는 데이터를 미리 가져다놓는다. 이렇게 미리 가져오는 작업을 ‘미리 가져오기(prefetch)’라고 한다.

33. 캐시는 CPU 안에 있으며 CPU 내부 버스의 속도로 작동한다. 메모리의 경우 시스템 버스의 속도로 작동하기 때문에 느리다. 캐시는 빠른 속도로 작동하는 CPU와 느린 속도로 작동하는 메모리 사이에서 두 장치의 속도 차이를 완화해준다.

34. 캐시는 메모리의 내용 중 일부를 미리 가져오고, CPU는 메모리에 접근해야 할 때 캐시를 먼저 방문하여 원하는 데이터가 있는지 찾아본다. 캐시에서 원하는 데이터를 찾았다면 캐시 히트(cache hit)라고 하며, 그 데이터를 바로 사용한다. 그러나 원하는 데이터가 캐시에 없으면 메모리로 가서 데이터를 찾는데 이를 캐시 미스(cache miss)라고 한다. 캐시 히트가 되는 비율을 캐시 적중률(cache hit ratio)이라고 하며, 일반적인 컴퓨터의 캐시 적중률은 약 90%이다.

35. 컴퓨터의 성능을 향상하려면 캐시 적중률이 높아야 한다. 캐시 적중률을 높이는 방법 중 하나는 캐시의 크기를 늘리는 것이다. 캐시의 크기가 커지면 더 많은 데이터를 미리 가져올 수 있어 캐시 적중률이 올라간다. 클록이 같은 CPU라도 저가형과 고가형은 캐시의 크기가 다르다.

36. 즉시 쓰기와 지연 쓰기  
캐시에 있는 데이터가 변경되는 경우 이를 반영해야 하는 문제도 있다. 캐시는 메모리에 있는 데이터를 임시로 가져온 것이기 때문에 캐시에 있는 데이터가 변경되면 메모리에 있는 원래 데이터를 변경해야 한다. 캐시의 변경된 데이터를 메모리에 반영하는 데에는 즉시 쓰기 방식과 지연 쓰기 방식이 있다.

37. 웹 브라우저 캐시  
캐시는 소프트웨어적으로도 사용되는데 대표적인 예가 웹 브라우저 캐시이다. 웹에서 사용하는 캐시는 ‘앞으로 다시 방문할 것을 예상하여 지우지 않는 데이터’라고 정의할 수 있다. 다음이나 네이버와 같이 자주 방문하는 사이트의 경우 로고나 버튼 등의 작은 그림이 자주 바뀌지 않는데, 로고나 버튼 등의 데이터를 캐시에 보관하고 있다가 사이트를 다시 방문하면 캐시에 있는 데이터를 사용하여 속도를 높인다. 이처럼 웹 브라우저의 캐시는 방문했던 사이트의 데이터를 보관하여 재방문 시 속도를 높이는 역할을 한다. 그러나 너무 많은 데이터가 캐시에 보관되어 있으면 웹 브라우저의 속도를 떨어뜨릴 수 있으므로 가끔 청소를 하는 것이 좋다.

38. 인터럽트  
입출력 관리자가 CPU에 보내는 완료 신호를 인터럽트라고 한다. CPU는 입출력 관리자에게 작업 지시를 내리고 다른 일을 하다가 완료 신호를 받으면 하던 일을 중단하고 옮겨진 데이터를 처리한다. 이처럼 하던 작업을 중단하고 처리해야 하는 신호라는 의미에서 인터럽트라고 불리게 되었다.

39. 직접 메모리 접근(DMA, Direct Memory Access)  
입출력이 필요할 때 CPU는 입출력 관리자에게 입출력 요청을 보내고 자신은 하던 일을 계속한다. 명령을 받은 입출력 관리자는 CPU가 요청한 데이터를 메모리에 가져다 놓아야 하는데 이때 문제가 있다. 메모리는 CPU만 접근 권한을 가진 작업 공간이라 입출력 관리자는 접근이 불가하다는 것이다. 따라서 입출력 관리자에게는 CPU의 허락 없이 메모리에 접근할 수 있는 권한이 필요한데, 이러한 권한을 직접 메모리 접근이라고 한다.

### 4. 병렬 처리
40. 병렬 처리에서 작업을 N개로 쪼갰을 때 N을 병렬 처리의 깊이(depth of parallel processing)라고 한다.

41. 병렬 처리의 깊이 N은 동시에 처리할 수 있는 작업의 개수를 의미한다.

42. 이론적으로는 N이 커질수록 동시에 작업할 수 있는 작업의 개수가 많아져서 성능이 높아질 것이다. 하지만 작업을 너무 많이 나누면 각 단계마다 작업을 이동하고 새로운 작업을 불러오는 데 시간이 너무 많이 걸려서 오히려 성능이 떨어진다. 이러한 오버헤드를 고려하여 보통 병렬 처리의 깊이를 10~20정도로 한다.

43. 병렬 처리 기법  
CPU 내에서 명령어는 제어장치가 처리한다. 제어장치는 명령어를 가져와 해석한 후 실행하고 결과를 저장하는 과정을 계속 반복한다. 이러한 과정 전체를 하나의 스레드라고 하며, 스레드를 이루는 각 단계는 CPU의 클록과 연동되어 한 클록에 한 번씩 이루어진다.

44. CPU는 이러한 단계를 계속 반복하면서 명령어를 처리한다.
1) 명령어 패치(Instruction Fetch, IF) : 다음에 실행할 명령어를 명령어 레지스터에 저장한다.
2) 명령어 해석(instruction Decode, ID) : 명령어를 해석한다.
3) 실행(Execution, EX) : 해석한 결과를 토대로 명령어를 실행한다.
4) 쓰기(Write Back, WB) : 실행된 결과를 메모리에 저장한다.

45. 병렬 처리 기법은 하나의 코어에서 작업을 나누어 병렬로 처리하는 파이프라인 기법과 여러 개의 코어를 사용하여 동시에 작업을 진행하는 슈퍼스칼라 기법으로 나뉜다.

46. 파이프라인(pipeline) 기법  
파이프라인 기법은 CPU의 사용을 극대화하기 위해 명령을 겹쳐서 실행하는 방법으로, CPU의 사양과 연관지어 보면 하나의 코어에 여러 개의 스레드를 사용하는 것이다.

### 5. 무어의 법칙과 암달의 법칙
47. 인텔의 공동 창업자인 고든 무어(Gordon Moore)는 CPU의 속도가 24개월마다 2배 빨라진다는 무어의 법칙을 주장했다. 그러나 이 주장은 초기의 CPU에만 적용되며 지금은 그렇지 않다. CPU는 자체 발열 문제로 속도를 5GHz 이상 높이기 어렵기 때문에 요즘에는 처리 속도를 올리는 대신 멀티코어를 장착하는 방향으로 나아가고 있다.

48. 멀티코어와 함께 멀티스레드도 많이 사용되고 있다. 멀티스레드는 하나의 코어에서 여러 개의 명령어를 실행하는 기술이다.

49. 암달의 법칙(Amdahl’s law)  
진 암달(Gene Amdahl)은 컴퓨터 시스템의 일부를 개선할 때 전체 시스템에 미치는 영향과의 관계를 수식으로 나타낸 암달의 법칙을 만들었다. 이 법칙에 따르면 주변장치의 향상 없이 CPU의 속도를 2GHz에서 4GHz로 늘리더라도 컴퓨터의 성능이 2배 빨라지지 않는다. 앞에서도 설명했듯이 CPU의 속도를 올린다고 해도 메모리를 비롯한 주변장치가 CPU의 발전 속도를 따라가지 못해 컴퓨터의 전반적인 성능이 저하되는 것이다. 암달의 법칙은 멀티코어에도 적용되는데, 코어가 하나인 싱글코어 대신 듀얼코어를 사용하더라도 CPU 내 다른 부품의 병목 현상으로 인해 CPU의 성능이 2배가 되지 않는다.

# Part2. 프로세스 관리
# Chapter 3. 프로세스와 스레드
### 1. 프로세스 개요
50. 프로그램은 저장장치에 저장되어 있는 정적인 상태이고, 프로세스는 실행을 위해 메모리에 올라온 동적인 상태이다.
우리는 프로그램을 ‘짠다’ 또는 ‘작성한다’라고 표현한다. 프로그램이란 어떤 데이터를 사용하여 어떤 작업을 할지 그 절차를 적어놓은 것이다. 반면에 프로세스는 ‘실행한다’라고 표현하는데, 이는 프로그램으로 작성된 작업 절차를 실제로 실행에 옮긴다는 의미이다. 다라서 누군가가 작성한 프로그램이 실행되면 프로세스가 된다.

51. 프로세스 제어블록(Process Control Block, PCB)에 있는 다양한 정보 중 대표적인 세 가지는 다음과 같다.
1)프로세스 구분자 : 메모리에는 여러 개의 프로세스가 존재하므로 각 프로세스를 구분하는 구분자(ID)가 필요하다. 레스토랑의 주문서에 일련번호가 있듯이 프로세스를 구분하기 위해 프로세스 구분자(Process Identification, PID)가 있다.
2)메모리 관련 정보 : CPU는 실행하려는 프로세스가 메모리의 어디에 저장되어 있는지를 알아야 작업을 할 수 있다. 이를 위해 프로세스 제어 블록에는 프로세스의 메모리 위치 정보가 담겨 있다. 또한 메모리 보호를 위한 경계 레지스터와 한계 레지스터도 포함되어 있다.
3)각종 중간값 : 프로세스 제어 블록에는 프로세스가 사용했던 중간값이 저장되는데, 이는 현재 어떤 단품 요리까지 손님에게 제공되었는지 주문서에 표시하는 것과 유사하다. 시분할 시스템에서는 여러 프로세스가 번갈아가며 실행되기 때문에 각 프로세스는 일정 시간 작업을 한 후 다른 프로세스에 CPU를 넘겨준다.

51. 프로그램이 프로세스가 된다는 것은 운영체제로부터 프로세스 제어 블록을 얻는다는 뜻이고, 프로세스가 종료된다는 것은 해당 프로세스 제어 블록이 폐기된다는 뜻이다.

52. 프로세스의 상태와 관련된 작업  
- 생성 상태 : 프로그램을 메모리에 가져와 실행 준비가 완료된 상태이다.(메모리 할당, 프로세스 제어 블록 생성)
- 준비 상태 : 실행을 기다리는 모든 프로세스가 자기 차례를 기다리는 상태이다. 실행될 프로세스를 CPU 스케줄러가 선택한다.(dispatch(PID):준비 -> 실행)
- 실행 상태 : 선택된 프로세스가 타임 슬라이스를 얻어 CPU를 사용하는 상태이다. 프로세스 사이의 문맥 교환이 일어난다.(timeout(PID):실행 -> 준비, exit(PID):실행 -> 완료, block(PID):실행 -> 대기)
- 대기 상태 : 실행 상태에 있는 프로세스가 입출력을 요청하면 입출력이 완료될 때까지 기다리는 상태이다. 입출력이 완료되면 준비 상태로 간다.(wakeup(PID):대기 -> 준비)
- 완료 상태 : 프로세스가 종료된 상태이다. 사용하던 모든 데이터가 정리된다. 정상 종료인 exit와 비정상 종료인 abort를 포함한다.(메모리 삭제, 프로세스 제어 블록 삭제)

53. 실행상태(running status)  
실행 상태는 프로세스가 CPU를 할당받아 실행되는 상태이다. 준비 상태에 있는 많은 프로세스 중 실행 상태에 들어가는 프로세스는 CPU의 개수 만큼이다. 실행 상태에 있는 프로세스는 자신에게 주어진 시간, 즉 타임 슬라이스 동안만 작업할 수 있다. 그 시간을 다 사용하면 timeout(PID)가 실행된다. Timeout(PID)는 프로세스 제어 블록을 실행 상태에서 준비 상태로 옮긴다. 만약 실행 상태 동안 작업이 완료되면 exit(PID)가 실행되어 프로세스가 정상 종료된다.

54. 보류 상태(suspend status)  
보류 상태는 프로세스가 메모리에서 잠시 쫓겨난 상태로 휴식 상태와 차이가 있따. 보류 상태는 ‘일시 정지 상태’라고도 불리며, 보류 상태와 비교하여 일반적인 프로세스 상태를 활성 상태라고 한다. 프로세스는 다음과 같은 경우에 보류 상태가 된다.
- 메모리가 꽉 차서 일부 프로세스를 메모리 밖으로 내보낼 때
- 프로그램에 오류가 있어서 실행을 미루어야 할 때
- 바이러스와 같이 악의적인 공격을 하는 프로세스라고 판단될 때
- 매우 긴 주기로 반복되는 프로세스라 메모리 밖으로 쫓아내도 큰 문제가 없을 때
- 입출력을 기다리는 프로세스의 입출력이 계속 지연될 때

55. 보류 상태와 휴식 상태를 구분하자면, 보류 상태는 스왑 영역에 있는 상태이고 휴식 상태는 프로세스가 메모리에 있으나 멈춘 상태이다.

### 2. 프로세스 제어 블록과 문맥 교환
56. 프로세스 제어 블록(PCB)  
프로세스 제어블록은 프로세스를 실행하는 데 필요한 중요한 정보를 보관하는 자료 구조로 TCB(Task Control Block)라고도 한다. 모든 프로세스는 고유의 프로세스 제어 블록을 가지며, 프로세스 제어 블록은 프로세스 생성 시 만들어져서 프로세스가 실행을 완료하면 폐기된다.

57. 문맥 교환(Context Switching)은 CPU를 차지하던 프로세스가 나가고 새로운 프로세스를 받아들이는 작업을 말한다. 이때 두 프로세스 제어 블록의 내용이 변경된다.

58. 문맥 교환이 일어나는 경우는 매우 다양하다. 일반적으로 한 프로세스가 자신에게 주어진 시간을 다 사용하면 발생하고, 인터럽트가 걸렸을 때도 발생한다. 예를 들어 어떤 프로세스가 자신에게 주어진 메모리 공간을 넘어가려 한다면 이는 경계 레지스터의 범위를 벗어나는 것이다. 이때 인터럽트가 발생하여 현재 실행 중인 프로세스의 제어 블록을 저장한 후 인터럽트 관리 프로세스를 실행 상태로 만든다. 인터럽트 관리 프로세스는 메모리 범위를 넘어선 프로세스를 강제로 종료하고 인터럽트 처리를 마치는데, 이와 같이 인터럽트 처리를 할 때도 문맥 교환이 일어난다.

### 3. 프로세스의 연산
59. 프로세스의 구조  
- 코드 영역(code area)  
코드 영역은 프로그램의 본문이 기술된 곳으로 텍스트 영역(text area)이라고도 한다. 프로그래머가 작성한 프로그램은 코드 영역에 탑재되며 탑재된 코드는 읽기 전용으로 처리된다. 자기 자신을 수정하는 프로그램은 존재하지 않기 때문이다.
- 데이터 영역(data area)  
데이터 영역은 코드가 실행되면서 사용하는 변수나 파일 등의 각종 데이터를 모아놓은 곳이다. 데이터는 변하는 값이기 때문에 이곳의 내용은 기본적으로 읽기와 쓰기가 가능하다. 물론 상수로 선언된 변수는 읽기 전용이지만 대부분의 변수는 읽기와 쓰기가 가능하다.
- 스택 영역(stack area)  
스택 영역은 운영체제가 프로세스를 실행하기 위해 부수적으로 필요한 데이터를 모아놓은 곳이다. 예를 들어 프로세스 내에서 함수를 호출하면(function call) 함수를 수행하고 원래 프로그램으로 되돌아올 위치를 이 영역에 저장한다. 스택 영역은 운영체제가 사용자의 프로세스를 작동하기 위해 유지하는 영역이므로 사용자에게는 보이지 않는다.

60. fork() 시스템 호출  
fork() 시스템 호출은 실행 중인 프로세스를 복사하는 함수이다. 이때 실행하던 프로세스는 부모 프로세스, 새로 생긴 프로세스는 자식 프로세스로서 부모-자식 관계가 된다.

61. fork() 시스템 호출의 장점  
프로세스를 새로 만들지 않고 fork() 시스템 호출로 프로세스를 복사하면 다음과 같은 장점이 있다.
- 프로세스의 생성 속도가 빠르다.  
하드디스크로부터 프로그램을 새로 가져오지 않고 기존 메모리에서 복사하기 때문에 자식 프로세스의 생성 속도가 빠르다. 워드프로세서 프로그램을 2개 실행했을 때 첫 번째 것보다 두 번째 것의 실행 속도가 더 빠른 것을 경험해보았을 것이다.
- 추가 작업 없이 자원을 상속할 수 있다.  
부모 프로세서가 사용하던 모든 자원을 추가 작업 없이 자식 프로세스에 상속할 수 있다. 예를 들어 부모 프로세스가 파일 A를 사용하기 위해 초기화했다면 자식 프로세스는 파일 A를 바로 사용할 수 있다.
- 시스템 관리를 효율적으로 할 수 있다.  
부모 프로세스와 자식 프로세스가 자식 프로세스 구분자와 부모 프로세스 구분자로 연결되어 있기 때문에, 자식 프로세스를 종료하면 자식이 사용하던 자원을 부모 프로세스가 정리할 수 있다. 프로세스를 종료하면 프로세스가 사용하던 메모리 영역, 파일, 하드웨어를 잘 정리해야 하는데, 이러한 정리를 부모 프로세스에 맡김으로써 시스템이 효율적으로 관리 되는 것이다.

62. exec(): 프로세스는 그대로 둔 채 내용만 바꾸는 시스템 호출이다. exec() 시스템 호출을 하면 현재의 프로세스가 완전히 다른 프로세스로 전환된다.

63. exec() 시스템 호출을 사용하는 목적은 프로세스의 구조체를 재활용하기 위함이다. 새로운 프로세스를 만들려면 프로세스 제어 블록을 만들고 메모리의 자리를 확보하는 과정이 필요하다. 또한 프로세스를 종료한 후 사용한 메모리를 청소(garbage collection)하기 위해 상위 프로세스와 부모-자식 관계를 만들어야 한다. 이때 exec() 시스템 호출을 사용하면 이미 만들어진 프로세스 제어 블록, 메모리 영역, 부모-자식 관계를 그대로 사용할 수 있어 편리하다. 새로운 코드 영역만 가져오면 되기 때문에 운영체제의 작업이 수월하다.

64. 프로세스를 계층 구조로 만들면 프로세스 간의 책임 관계가 분명해져서 시스템을 관리하기가 수월하다. 프로세스가 작업을 마쳐서 그 프로세스가 사용하던 자원을 회수(garbage collection)할 때 특히 편리하다. 만약 모든 프로세스가 독립적으로 만들어지면 프로세스가 종료될 때마다 운영체제가 직접 자원을 회수해야 하기 때문에 작업이 복잡해질 것이다. 그러나 모든 프로세스를 부모-자식 관계로 만들면 자식 프로세스가 작업을 마쳤을 때 사용하던 자원을 부모 프로세스가 회수하면 된다.

### 4. 스레드
65. 프로세스는 요리 작업 전체와 같고, 스레드는 요리를 완성하기 위해 수행하는 각각의 조리에 해당하는 것이다.

66. 운영체제는 코드와 데이터를 메모리에 가져오고, 프로세스 제어 블록을 생성하고, 작업에 필요한 메모리 영역을 확보한 후, 준비된 프로세스를 준비 큐에 삽입한다. 프로세스가 생성되면 CPU 스케줄러는 프로세스가 해야 할 일을 CPU에 전달하고 실제 작업은 CPU가 수행한다. 이때 CPU 스케줄러가 CPU에 전달하는 일 하나가 스레드이다. 그러므로 CPU가 처리하는 작업의 단위는 프로세스로부터 전달받은 스레드이다. 그러므로 CPU가 처리하는 작업의 단위는 프로세스로부터 전달받은 스레드이다. 운영체제 입장에서의 작업 단위는 프로세스이고 CPU 입장에서의 작업 단위는 스레드인 것이다. 프로세스 입장에서는 스레드를 다음과 같이 정의할 수 있다.

67. 스레드  
프로세스의 코드에 정의된 절차에 따라 CPU에 작업 요청을 하는 실행 단위이다.

68. 작업의 크기  
작업을 상대적인 크기순으로 나열하면 job > task > operation이고, 이를 프로세스와 스레드의 관계에 대입하면 처리(job) > 프로세스(task) >스레드(operation)가 된다. 여러 개의 스레드가 모여 프로세스를 이루고 여러 개의 프로세스가 모여 처리가 되며, 여러 개의 프로세스를 모아서 한꺼번에 처리하는 방법을 일괄 작업(batch job)이라고 한다.

69. 개개의 프로세스와 스레드는 서로서로 미치는 영향이 다르다. 프로세스끼리는 약하게 연결되어 있는 반면 스레드끼리는 강하게 연결되어 있다.

70. 멀티태스크  
워드프로세서와 프린터 스풀러는 서로 독립적으로 작동하다가 필요할 때 출력하 데이터를 주고받는다. 서로 독립적이라는 것은 워드프로세서가 비정상적으로 종료되어도 프린터 스풀러는 정상적으로 작동한다는 의미이다. 이렇게 서로 독립적인 프로세스는 데이터를 주고받을 때 프로세스 간 통신(Inter Process Communication, IPC)을 이용한다.

71. 멀티스레드  
워드프로세서 프로세스 내의 문서 편집, 문서 입출력, 맞춤법 검사, 그림판 같은 스레드들이 동시에 작업을 하는 멀티스레드를 나타낸 것이다. 이러한 스레드들은 강하게 연결되어 있으므로 워드프로세서가 종료되면 프로세스 내의 스레드도 강제 종료된다. 멀티스레드는 변수나 파일 등을 공유하고 전역 변수나 함수 호출 등의 방법으로 스레드 간 통신을 한다.

72. 멀티스레드  
운영체제가 소프트웨어적으로 프로세스를 작은 단위의 스레드로 분할하여 운영하는 기법이다.

73. CPU 멀티스레드  
하드웨어적인 방법으로 하나의 CPU에서 여러 스레드를 동시에 처리하는 병렬 처리 기법이다.

74. 커널 스레드  
커널이 직접 생성하고 관리하는 스레드이다.

75. 사용자 스레드  
라이브러리에 의해 구현된 일반적인 스레드이다.
 
### 5. 동적 할당 영역과 시스템 호출
76. 자식의 자원을 정리해야 할 부모 프로세스가 먼저 종료되면 자식 프로세스의 exit() 함수는 돌아갈 곳이 없는데 이러한 프로세스가 바로 미아 프로세스(Orphan Process)이다. 물론 반환되지 못한 자원은 나중에 운영체제의 자원 회수로 처리되겠지만, 미아 프로세스가 많이 발생하면 시스템의 자원이 낭비된다.


# Chapter 4. CPU 스케줄링
### 1. 스케줄링의 개요
### 2. 스케줄링 시 고려 사항
### 3. 다중 큐
### 4. 스케줄링 알고리즘
### 5. 인터럽트 처리

# Chapter 5. 프로세스 동기화
### 1. 프로세스 간 통신
### 2. 공유 자원과 임계구역
### 3. 임계구역 해결 방법
### 4. 파일, 파이프, 소켓 프로그래밍

# Chapter 6. 교착 상태
### 1. 교착 상태의 개요
### 2. 교착 상태 필요조건
### 3. 교착 상태 해결 방법
### 4. 다중 자원과 교착 상태 검출


# Part3. 메모리 관리
# Chapter 7. 물리 메모리 관리
### 1. 메모리 관리의 개요
### 2. 메모리 주소
### 3. 단일 프로그래밍 환경에서의 메모리 할당
### 4. 다중 프로그래밍 환경에서의 메모리 할당
### 5. 컴파일과 메모리 관리

# Chapter 8. 가상 메모리 기초
### 1. 가상 메모리 개요
### 2. 페이징 기법
### 3. 세그먼테이션 기법
### 4. 세그먼테이션-페이징 혼용 기법
### 5. 캐시 매핑 기법

# Chapter 9. 가상 메모리 관리
### 1. 요구 페이징
### 2. 페이지 교체 알고리즘
### 3. 스레싱과 프레임 할당
### 4. 프레임 관련 이슈


# Part4. 저장장치 관리
# Chapter 10. 입출력 시스템과 저장장치
### 1. 입출력 시스템
### 2. 디스크 장치
### 3. 디스크 스케줄링
### 4. RAID
### 5. 하드웨어의 규격과 발전

# Chapter 11. 파일 시스템
### 1. 파일과 파일 시스템
### 2. 디렉터리의 구조
### 3. 디스크 파일 할당
### 4. 유닉스 파일의 특징

# Part5. 분산 시스템
# Chapter 12. 네트워크와 분산 시스템
### 1. 네트워크와 인터넷
### 2. 분산 시스템
### 3. 분산 시스템의 고가용성

#운영체제#조성호


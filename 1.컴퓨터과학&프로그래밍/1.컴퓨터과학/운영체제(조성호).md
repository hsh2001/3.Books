# 운영체제
### 지은이 : 조성호
### 출판사 : 한빛아카데미
### 읽은 날 : 2020.02.22 ~

<목차>
# Part1. 운영체제와 컴퓨터
### Chapter 1. 운영체제의 개요
1. 운영체제 소개
2. 운영체제의 역사
3. 운영체제의 구조
4. 운영체제의 종류와 역사

### Chapter 2. 컴퓨터 구조와 성능 향상
1. 컴퓨터의 기본 구성
2. CPU와 메모리
3. 컴퓨터 성능 향상 기술
- 버퍼
- 캐시
- 저장장치의 개층 구조
- 인터럽트
4. 병렬 처리
5. 무어의 법칙과 암달의 법칙


# Part2. 프로세스 관리
### Chapter 3. 프로세스와 스레드
1. 프로세스 개요
2. 프로세스 제어 블록과 문맥 교환
3. 프로세스의 연산
4. 스레드
5. 동적 할당 영역과 시스템 호출

### Chapter 4. CPU 스케줄링
1. 스케줄링의 개요
2. 스케줄링 시 고려 사항
3. 다중 큐
4. 스케줄링 알고리즘
5. 인터럽트 처리

### Chapter 5. 프로세스 동기화
1. 프로세스 간 통신
2. 공유 자원과 임계구역
3. 임계구역 해결 방법
4. 파일, 파이프, 소켓 프로그래밍

### Chapter 6. 교착 상태
1. 교착 상태의 개요
2. 교착 상태 필요조건
3. 교착 상태 해결 방법
4. 다중 자원과 교착 상태 검출


#Part3. 메모리 관리
### Chapter 7. 물리 메모리 관리
1. 메모리 관리의 개요
2. 메모리 주소
3. 단일 프로그래밍 환경에서의 메모리 할당
4. 다중 프로그래밍 환경에서의 메모리 할당
5. 컴파일과 메모리 관리

### Chapter 8. 가상 메모리 기초
1. 가상 메모리 개요
2. 페이징 기법
3. 세그먼테이션 기법
4. 세그먼테이션-페이징 혼용 기법
5. 캐시 매핑 기법

### Chapter 9. 가상 메모리 관리
1. 요구 페이징
2. 페이지 교체 알고리즘
3. 스레싱과 프레임 할당
4. 프레임 관련 이슈


# Part4. 저장장치 관리
### Chapter 10. 입출력 시스템과 저장장치
1. 입출력 시스템
2. 디스크 장치
3. 디스크 스케줄링
4. RAID
5. 하드웨어의 규격과 발전

### Chapter 11. 파일 시스템
1. 파일과 파일 시스템
2. 디렉터리의 구조
3. 디스크 파일 할당
4. 유닉스 파일의 특징

# Part5. 분산 시스템
### Chapter 12. 네트워크와 분산 시스템
1. 네트워크와 인터넷
2. 분산 시스템
3. 분산 시스템의 고가용성

-------------------------------------------
# Part1. 운영체제와 컴퓨터
# Chapter 1. 운영체제의 개요
### 1. 운영체제 소개
1. 펌웨어  
운영체제는 우리가 사용하는 각종 소프트웨어 중 하나이다. 게임이나 문서 편집기 같은 소프트웨어가 특정 목적을 위해 존재한다면, 운영체제는 컴퓨터에 있는 하드웨어(자원)를 조정하고 관리하기 위해 존재한다. 그런데 운영체제는 하드웨어를 조정하고 관리하는 역할을 하므로 하드웨어의 도움 없이 작동하기가 어렵기 때문에 운영체제를 소프트웨어와 하드웨어로 결합한 형태인 펌웨어(firmware)라고 부르기도 한다.

2. 운영체제는 하드웨어 인터페이스가 자동으로 설치되게 함으로써 하드웨어의 종류에 상관없이 사용할 수 있게 해준다.

### 2. 운영체제의 역사
3. 천공카드 리더로 하나의 작업을 읽어들여 실행하고 결과를 출력한 후 다음 작업을 읽어들여 실행했다. 이러한 시스템에서는 작업에 필요한 프로그램과 데이터를 동시에 입력해야 작업이 가능하다. 지금의 프로그래밍 환경과 달리 모든 작업을 한꺼번에 처리해야 하고 프로그램 실행 중간에 사용자가 데이터를 입력하거나 수정하는 것이 불가능한데, 이러한 시스템을 일괄 작업 시스템(batch job system)또는 일괄 처리 시스템(batch processing system)이라고 부른다.

4. 이처럼 여러 작업을 조금씩 처리하여 작업이 동시에 이루어지는 것처럼 보이게 하는 것을 시분할 시스템(time sharing system)이라고 한다. 다중 작업(multitasking)시스템이라고도 불리는 시분할 시스템에서는 CPU 사용 시간을 잘게 나뉜 시간 한 조각을 타임 슬라이스(time slice)또는 타임 퀀텀(time quantum)이라고 한다. 오늘날의 컴퓨터에는 대부분 시분할 시스템이 사용된다.

### 3. 운영체제의 구조
5. 시스템 호출(system call)  
시스템 호출은 커널이 자신을 보호하기 위해 만든 인터페이스이다. 커널은 사용자나 응용 프로그램으로부터 컴퓨터 자원을 보호하기 위해 자원에 직접 접근하는 것을 차단한다. 따라서 자원을 이용하려면 시스템 호출이라는 인터페이스를 이용하여 접근해야 한다.

6. 시스템 호출에 관한 내용을 정리하면 다음과 같다.
- 시스템 호출은 커널이 제공하는 시스템 자원의 사용과 연관된 함수이다.
- 응용 프로그램이 하드웨어 자원에 접근하거나 운영체제가 제공하는 서비스를 이용하려 할 때는 시스템 호출을 사용해야 한다.
- 운영체제는 커널이 제공하는 서비스를 시스템 호출로 제한하고 다른 방법으로 커널에 들어오지 못하게 막음으로써 컴퓨터 자원을 보호한다.
- 시스템 호출은 커널이 제공하는 서비스를 이용하기 위한 인터페이스이며, 사용자가 자발적으로 커널 영역에 진입할 수 있는 유일한 수단이다.

7. 시스템 호출 부분을 보면 커널 앞부분 전체를 감싸고 있는데, 이는 시스템 호출을 거치지 않고 커널에 진입할 수 없다는 의미이다. 반면에 드라이버는 커널 전체를 감싸고 있지 않다. 이는 커널이 제공하는 드라이버도 있고 하드웨어 제작자가 제공하는 드라이버도 있다는 뜻으로, 하드웨어는 커널과 직접 연결되기도 하고 하드웨어 제작자가 제공하는 드라이버를 통해 연결되기도 한다.

8. 커널이 하는 일  
- 프로세스 관리 : 프로세스에 CPU를 배분하고 작업에 필요한 제반 환경을 제공한다.
- 메모리 관리 : 프로세스에 작업 공간을 배치하고 실제 메모리보다 큰 가상공간을 제공한다.
- 파일 시스템 관리 : 데이터를 저장하고 접근할 수 있는 인터페이스를 제공한다.
- 입출력 관리 : 필요한 입력과 출력 서비스를 제공한다.
- 프로세스 간 통신 관리 : 공동 작업을 위한 각 프로세스 간 통신 환경을 지원한다.

9. 이런 호환성 문제를 해결한 언어가 바로 자바이다. 자바로 프로그래밍을 하면 대부분의 운영체제에서 작동하기 때문에 코드를 수정할 필요가 없다. 자바가 작동하는 원리는 매우 간단하다. 운영체제 위에 가상머신을 만들고 그 위에서 응용 프로그램이 작동하게 하는 것이다.

10. 가상머신의 개념은 다양한 곳에서 사용된다. 예를 들어 윈도우 운영체제 환경에서 유닉스를 사용하고 싶다고 가정해보자. 이 경우 윈도우 운영체제와 유닉스 운영체제를 같이 설치하고 부팅할 때 어떤 운영체제를 사용할지 선택해야 한다. 그러나 대부분의 작업을 윈도우에서 하고 유닉스는 가끔 사용한다면 하나의 컴퓨터에 두 가지 운영체제를 설치하기가 부담스러운데, 이럴 때는 윈도우 운영체제에 유닉스 가상머신을 설치하여 사용하면 된다. 가상머신을 사용하면 호환성이 높아지지만 응용 프로그램이 가상머신을 통해서만 작동하기 때문에 느려진다는 단점도 있다.

11. 커널의 종류
- 단일형 구조 커널 : 커널의 핵심 기능을 구현하는 모듈들이 구분 없이 하나로 구성되어 있다.
- 계층형 구조 커널 : 비슷한 기능을 가진 모듈을 묶어서 하나의 계층으로 만들고 계층 간의 통신을 통해 운영체제를 구현하는 방식이다.
- 마이크로 구조 커널 : 운영체제가 프로세스 관리, 메모리 관리, 프로세스 간 통신 관리 등 가장 기본적인 기능만 제공한다.

### 4. 운영체제의 종류와 역사

# Chapter 2. 컴퓨터 구조와 성능 향상
### 1. 컴퓨터의 기본 구성
12. 폰노이만 구조에서 가장 중요한 특징은, ‘모든 프로그램은 메모리에 올라와야 실행할 수 있다’는 것이다.

13. 클록(clock)  
클록은 CPU 속돵 관련된 단위이다. 다양한 악기로 조합된 오케스트라는 박자가 맞아야 제대로 곡을 연주할 수 있듯이 CPU도 작업을 할 때 일정한 박자가 있는데, 이 박자를 만들어내는 것이 클록이다. 클록이 일정한 간격으로 틱(tick)을 만들면 거기에 맞추어 CPU안의 모든 구성 부품이 작업을 한다. 틱은 펄스(pulse) 또는 클록틱(clock tick)이라고도 부른다. 버스에는 여러 개의 부품이 연결되어 있는데, 메인보드의 클록이 틱을 보낼 때마다 데이터를 보내거나 받는다.

14. 헤르츠(Hz)  
헤르츠는 클록틱이 발생하는 속도를 나타내는 단위이다. 1초에 클록틱이 몇 번 발생하는지를 나타내는데, 1초에 클록틱이 한 번이면 1Hz, 1000번이면 1kHz이다.

15. 시스템 버스(system bus)와 CPU 내부 버스  
시스템 버스는 메모리와 주변장치를 연결하는 버스로 FSB(Front-Side Bus), 즉 전면 버스라고 한다. 1,333MHz의 시스템 버스를 가진 메인보드에는 같은 속도를 가진 부품이 연결되고 메모리도 1,333MHz의 속도로 작동한다.

16. CPU 내부 버스는 CPU 내부에 있는 장치를 연결하는 버스로 BSB(Back-Side Bus), 즉 후면 버스라고 한다. CPU 내부 버스의 속도는 CPU 클록과 같아서 시스템 버스보다 훨씬 빠르다.

### 2. CPU와 메모리
17. CPU는 0과 1의 2진수로 이루어진 기계어(machine code)만 인식한다. 따라서 위 코드를 실행하려면 컴파일러를 이용하여 기계어로 바꾸어야 한다. 여기서는 사람이 이해하기 어려운 기계어 대신 어셈블리어로 작성한 코드를 살펴보자. 어셈블리어는 기계어를 사람이 이해하기 쉬운 기호와 일대일로 대응시켜 기호화한 언어이다.

18. 사용자 가시 레지스터  
- 데이터 레지스터(DR) : CPU가 명령어를 처리하는 데 필요한 일반 데이터를 임시로 저장하는 범용 레지스터이다.
- 주소 레지스터(AR) : 데이터 또는 명령어가 저장된 메모리 주소를 저장한다.

19. 사용자 불가시 레지스터  
- 프로그램 카운터(PC) : 다음에 실행할 명령어의 위치 정보(코드의 행 번호, 메모리 주소)를 저장한다.
- 명령어 레지스터(IR) : 현재 실행 중인 명령어를 저장한다.
- 메모리 주소 레지스터(MAR) : 메모리 관리자가 접근해야 할 메모리의 주소를 저장한다.
- 메모리 버퍼 레지스터(MBR) : 메모리 관리자가 메모리에서 가져온 데이터를 임시로 저장한다.
- 프로그램 상태 레지스터(PSR) : 연산 결과(양수, 음수 등)를 저장한다.

20. 제어 버스(control bus)  
제어 버스에서는 다음에 어떤 작업을 할지 지시하는 제어 신호가 오고 간다. … 제어 버스의 신호는 CPU, 메모리, 주변장치와 양방향으로 오고 간다.

21. 주소 버스(address bus)  
주소 버스에서는 메모리의 데이터를 읽거나 쓸 때 어느 위치에서 작업할 것인지를 알려주는 위치 정보(주소)가 오고 간다. … 주소 버스는 메모리 주소 레지스터와 연결되어 있으며 단방향이다. CPU에서 메모리나 주변장치로 나가는 주소 정보는 있지만 주소 버스를 통해 CPU로 전달되는 정보는 없다.

22. 데이터 버스(data bus)  
제어 버스가 다음에 어떤 작업을 할지 신호를 보내고 주소 버스가 위치 정보를 전달하면 데이터가 데이터 버스에 실려 목적지까지 이동한다. 데이터 버슨느 메모리 버퍼 레지스터와 연결되어 있으며 양방향이다.

23. 버스의 대역폭(bandwidth)은 한 번에 전달할 수 있는 데이터의 최대 크기를 말한다. … 흔히 32bit CPU, 64bit CPU라고 하는데 여기서 32bit, 64bit는 CPU가 한 번에 처리할 수 있는 데이터의 최대 크기이다. … 참고로 CPU가 한 번에 처리할 수 있는 데이터의 최대 크기를 워드(word)라고 하며, 버스의 대역폭과 메모리에 한 번에 저장되는 단위도 워드이다. 32bit CPU에서 1워드는 32bit이다.

24. 휘발성 메모리(volatility memory)  
휘발성 메모리에는 DRAM(Dynamic RAM, 동적 램)과 SRAM(Static RAM, 정적 램)이 있다. DRAM은 저장된 0과 1의 데이터가 일정 시간이 지나면 사라지므로 일정 시간마다 다시 재생시켜야 한다. DRAM의 ‘Dynamic’은 시간이 지나면 데이터가 사라지기 때문에 재생이 필요하다는 의미이다. SRAM은 전력이 공급되는 동안에는 데이터를 보관할 수 있어 재생할 필요가 없다. 따라서 속도는 빠르지만 가격이 비싸다. 일반적으로 메인메모리에는 DRAM을 사용하고, 캐시 같은 고속 메모리에는 SRAM을 사용한다.

25. 위 그림에서 B 작업의 메모리 시작 주소 140은 경계 레지스터에, B 작업의 크기 40은 한계 레지스터에 저장된다. B 작업이 데이터를 읽거나 쓸 때마다 CPU는 해당 작업이 경계 레지스터와 한계레지스터의 주소값 안에서 이루어지는지 검사한다. 만약 두 레지스터의 값을 벗어난다면 메모리 오류와 관련된 인터럽트가 발생한다. 인터럽트가 발생하면 모든 작업이 중단되고 CPU는 운영체제를 깨워서 인터럽트를 처리하도록 시킨다. 이처럼 모든 메모리 영역은 하드웨어와 운영체제의 협업에 의해 보호받는다.

26. 부팅(booting)  
컴퓨터를 켰을 때 운영체제를 메모리에 올리는 과정을 부팅이라고 한다.

27. 부트스트랩 코드는 운영체제를 메모리로 가져와 실행하는 역할을 하는 작은 프로그램이다.

### 3. 컴퓨터 성능 향상 기술
28. 현대 컴퓨터 구조의 가장 큰 문제는 CPU와 메모리, 주변장치의 작업 속도가 다르다는 것이다. 앞에서 살펴보았듯이 메인보드 내 메모리와 주변장치는 시스템 버스(FSB)로 연결되어 있고, CPU 내 레지스터, 산술논리 연산장치, 제어장치는 CPU 내부 버스(BSB)로 연결되어 있다. 따라서 메모리의 속도는 시스템 버스의 속도와 같고 CPU의 속도는 CPU 내부 버스의 속도와 같은데, CPU 내부 버스의 속도가 시스템 버스의 속도보다 빠르기 때문에 메모리를 비롯한 주변장치의 속도가 CPU의 속도를 따라가지 못한다. CPU에 비하면 메모리가 느린 것은 물론이고, 프로그램과 데이터를 보관하는 하드디스크의 속도는 더욱 느리다.

29. 버퍼(buffer)  
버퍼는 속도에 차이가 있는 두 장치 사이에서 그 차이를 완화하는 역할을 한다. … 일정량의 데이터를 모아 옮김으로써 속도 차이를 완화하는 장치가 버퍼이다.

30. 하드디스크에는 메모리 버퍼가 있다. 표2-2의 하드디스크 사양은 1TB, 7200rpm, 32MB인데, 이는 하드디스크의 용량이 1TB, 디스크의 회전 속도가 7500rpm, 버퍼의 용량이 32MB라는 의미이다. 같은 사양의 하드디스크라면 버퍼의 용량이 큰 것이 더 빠르다.

31. 스풀러는 일종의 버퍼이지만 기존의 버퍼와 다른 점이 있다. 버퍼의 경우 어떤 프로그램이 사용하는 데이터든 버퍼가 차면 이동이 시작된다. 다시 말해 프로그램들이 버퍼를 공유한다. 반면에 스풀러는 한 인쇄물이 완료될 때까지 다른 인쇄물이 끼어들 수 없으므로 프로그램 간에 배타적이다.

32. 캐시(cache)  
캐시는 메모리와 CPU 간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해두는 임시 장소이다. 캐시는 필요한 데이터를 모아 한꺼번에 전달하는 버퍼의 일종으로 CPU가 앞으로 사용할 것으로 예상되는 데이터를 미리 가져다놓는다. 이렇게 미리 가져오는 작업을 ‘미리 가져오기(prefetch)’라고 한다.

33. 캐시는 CPU 안에 있으며 CPU 내부 버스의 속도로 작동한다. 메모리의 경우 시스템 버스의 속도로 작동하기 때문에 느리다. 캐시는 빠른 속도로 작동하는 CPU와 느린 속도로 작동하는 메모리 사이에서 두 장치의 속도 차이를 완화해준다.

34. 캐시는 메모리의 내용 중 일부를 미리 가져오고, CPU는 메모리에 접근해야 할 때 캐시를 먼저 방문하여 원하는 데이터가 있는지 찾아본다. 캐시에서 원하는 데이터를 찾았다면 캐시 히트(cache hit)라고 하며, 그 데이터를 바로 사용한다. 그러나 원하는 데이터가 캐시에 없으면 메모리로 가서 데이터를 찾는데 이를 캐시 미스(cache miss)라고 한다. 캐시 히트가 되는 비율을 캐시 적중률(cache hit ratio)이라고 하며, 일반적인 컴퓨터의 캐시 적중률은 약 90%이다.

35. 컴퓨터의 성능을 향상하려면 캐시 적중률이 높아야 한다. 캐시 적중률을 높이는 방법 중 하나는 캐시의 크기를 늘리는 것이다. 캐시의 크기가 커지면 더 많은 데이터를 미리 가져올 수 있어 캐시 적중률이 올라간다. 클록이 같은 CPU라도 저가형과 고가형은 캐시의 크기가 다르다.

36. 즉시 쓰기와 지연 쓰기  
캐시에 있는 데이터가 변경되는 경우 이를 반영해야 하는 문제도 있다. 캐시는 메모리에 있는 데이터를 임시로 가져온 것이기 때문에 캐시에 있는 데이터가 변경되면 메모리에 있는 원래 데이터를 변경해야 한다. 캐시의 변경된 데이터를 메모리에 반영하는 데에는 즉시 쓰기 방식과 지연 쓰기 방식이 있다.

37. 웹 브라우저 캐시  
캐시는 소프트웨어적으로도 사용되는데 대표적인 예가 웹 브라우저 캐시이다. 웹에서 사용하는 캐시는 ‘앞으로 다시 방문할 것을 예상하여 지우지 않는 데이터’라고 정의할 수 있다. 다음이나 네이버와 같이 자주 방문하는 사이트의 경우 로고나 버튼 등의 작은 그림이 자주 바뀌지 않는데, 로고나 버튼 등의 데이터를 캐시에 보관하고 있다가 사이트를 다시 방문하면 캐시에 있는 데이터를 사용하여 속도를 높인다. 이처럼 웹 브라우저의 캐시는 방문했던 사이트의 데이터를 보관하여 재방문 시 속도를 높이는 역할을 한다. 그러나 너무 많은 데이터가 캐시에 보관되어 있으면 웹 브라우저의 속도를 떨어뜨릴 수 있으므로 가끔 청소를 하는 것이 좋다.

38. 인터럽트  
입출력 관리자가 CPU에 보내는 완료 신호를 인터럽트라고 한다. CPU는 입출력 관리자에게 작업 지시를 내리고 다른 일을 하다가 완료 신호를 받으면 하던 일을 중단하고 옮겨진 데이터를 처리한다. 이처럼 하던 작업을 중단하고 처리해야 하는 신호라는 의미에서 인터럽트라고 불리게 되었다.

39. 직접 메모리 접근(DMA, Direct Memory Access)  
입출력이 필요할 때 CPU는 입출력 관리자에게 입출력 요청을 보내고 자신은 하던 일을 계속한다. 명령을 받은 입출력 관리자는 CPU가 요청한 데이터를 메모리에 가져다 놓아야 하는데 이때 문제가 있다. 메모리는 CPU만 접근 권한을 가진 작업 공간이라 입출력 관리자는 접근이 불가하다는 것이다. 따라서 입출력 관리자에게는 CPU의 허락 없이 메모리에 접근할 수 있는 권한이 필요한데, 이러한 권한을 직접 메모리 접근이라고 한다.

### 4. 병렬 처리
40. 병렬 처리에서 작업을 N개로 쪼갰을 때 N을 병렬 처리의 깊이(depth of parallel processing)라고 한다.

41. 병렬 처리의 깊이 N은 동시에 처리할 수 있는 작업의 개수를 의미한다.

42. 이론적으로는 N이 커질수록 동시에 작업할 수 있는 작업의 개수가 많아져서 성능이 높아질 것이다. 하지만 작업을 너무 많이 나누면 각 단계마다 작업을 이동하고 새로운 작업을 불러오는 데 시간이 너무 많이 걸려서 오히려 성능이 떨어진다. 이러한 오버헤드를 고려하여 보통 병렬 처리의 깊이를 10~20정도로 한다.

43. 병렬 처리 기법  
CPU 내에서 명령어는 제어장치가 처리한다. 제어장치는 명령어를 가져와 해석한 후 실행하고 결과를 저장하는 과정을 계속 반복한다. 이러한 과정 전체를 하나의 스레드라고 하며, 스레드를 이루는 각 단계는 CPU의 클록과 연동되어 한 클록에 한 번씩 이루어진다.

44. CPU는 이러한 단계를 계속 반복하면서 명령어를 처리한다.
1) 명령어 패치(Instruction Fetch, IF) : 다음에 실행할 명령어를 명령어 레지스터에 저장한다.
2) 명령어 해석(instruction Decode, ID) : 명령어를 해석한다.
3) 실행(Execution, EX) : 해석한 결과를 토대로 명령어를 실행한다.
4) 쓰기(Write Back, WB) : 실행된 결과를 메모리에 저장한다.

45. 병렬 처리 기법은 하나의 코어에서 작업을 나누어 병렬로 처리하는 파이프라인 기법과 여러 개의 코어를 사용하여 동시에 작업을 진행하는 슈퍼스칼라 기법으로 나뉜다.

46. 파이프라인(pipeline) 기법  
파이프라인 기법은 CPU의 사용을 극대화하기 위해 명령을 겹쳐서 실행하는 방법으로, CPU의 사양과 연관지어 보면 하나의 코어에 여러 개의 스레드를 사용하는 것이다.

### 5. 무어의 법칙과 암달의 법칙
47. 인텔의 공동 창업자인 고든 무어(Gordon Moore)는 CPU의 속도가 24개월마다 2배 빨라진다는 무어의 법칙을 주장했다. 그러나 이 주장은 초기의 CPU에만 적용되며 지금은 그렇지 않다. CPU는 자체 발열 문제로 속도를 5GHz 이상 높이기 어렵기 때문에 요즘에는 처리 속도를 올리는 대신 멀티코어를 장착하는 방향으로 나아가고 있다.

48. 멀티코어와 함께 멀티스레드도 많이 사용되고 있다. 멀티스레드는 하나의 코어에서 여러 개의 명령어를 실행하는 기술이다.

49. 암달의 법칙(Amdahl’s law)  
진 암달(Gene Amdahl)은 컴퓨터 시스템의 일부를 개선할 때 전체 시스템에 미치는 영향과의 관계를 수식으로 나타낸 암달의 법칙을 만들었다. 이 법칙에 따르면 주변장치의 향상 없이 CPU의 속도를 2GHz에서 4GHz로 늘리더라도 컴퓨터의 성능이 2배 빨라지지 않는다. 앞에서도 설명했듯이 CPU의 속도를 올린다고 해도 메모리를 비롯한 주변장치가 CPU의 발전 속도를 따라가지 못해 컴퓨터의 전반적인 성능이 저하되는 것이다. 암달의 법칙은 멀티코어에도 적용되는데, 코어가 하나인 싱글코어 대신 듀얼코어를 사용하더라도 CPU 내 다른 부품의 병목 현상으로 인해 CPU의 성능이 2배가 되지 않는다.

# Part2. 프로세스 관리
# Chapter 3. 프로세스와 스레드
### 1. 프로세스 개요
50. 프로그램은 저장장치에 저장되어 있는 정적인 상태이고, 프로세스는 실행을 위해 메모리에 올라온 동적인 상태이다.
우리는 프로그램을 ‘짠다’ 또는 ‘작성한다’라고 표현한다. 프로그램이란 어떤 데이터를 사용하여 어떤 작업을 할지 그 절차를 적어놓은 것이다. 반면에 프로세스는 ‘실행한다’라고 표현하는데, 이는 프로그램으로 작성된 작업 절차를 실제로 실행에 옮긴다는 의미이다. 다라서 누군가가 작성한 프로그램이 실행되면 프로세스가 된다.

51. 프로세스 제어블록(Process Control Block, PCB)에 있는 다양한 정보 중 대표적인 세 가지는 다음과 같다.
1)프로세스 구분자 : 메모리에는 여러 개의 프로세스가 존재하므로 각 프로세스를 구분하는 구분자(ID)가 필요하다. 레스토랑의 주문서에 일련번호가 있듯이 프로세스를 구분하기 위해 프로세스 구분자(Process Identification, PID)가 있다.
2)메모리 관련 정보 : CPU는 실행하려는 프로세스가 메모리의 어디에 저장되어 있는지를 알아야 작업을 할 수 있다. 이를 위해 프로세스 제어 블록에는 프로세스의 메모리 위치 정보가 담겨 있다. 또한 메모리 보호를 위한 경계 레지스터와 한계 레지스터도 포함되어 있다.
3)각종 중간값 : 프로세스 제어 블록에는 프로세스가 사용했던 중간값이 저장되는데, 이는 현재 어떤 단품 요리까지 손님에게 제공되었는지 주문서에 표시하는 것과 유사하다. 시분할 시스템에서는 여러 프로세스가 번갈아가며 실행되기 때문에 각 프로세스는 일정 시간 작업을 한 후 다른 프로세스에 CPU를 넘겨준다.

52. 프로그램이 프로세스가 된다는 것은 운영체제로부터 프로세스 제어 블록을 얻는다는 뜻이고, 프로세스가 종료된다는 것은 해당 프로세스 제어 블록이 폐기된다는 뜻이다.

53. 프로세스의 상태와 관련된 작업  
- 생성 상태 : 프로그램을 메모리에 가져와 실행 준비가 완료된 상태이다.(메모리 할당, 프로세스 제어 블록 생성)
- 준비 상태 : 실행을 기다리는 모든 프로세스가 자기 차례를 기다리는 상태이다. 실행될 프로세스를 CPU 스케줄러가 선택한다.(dispatch(PID):준비 -> 실행)
- 실행 상태 : 선택된 프로세스가 타임 슬라이스를 얻어 CPU를 사용하는 상태이다. 프로세스 사이의 문맥 교환이 일어난다.(timeout(PID):실행 -> 준비, exit(PID):실행 -> 완료, block(PID):실행 -> 대기)
- 대기 상태 : 실행 상태에 있는 프로세스가 입출력을 요청하면 입출력이 완료될 때까지 기다리는 상태이다. 입출력이 완료되면 준비 상태로 간다.(wakeup(PID):대기 -> 준비)
- 완료 상태 : 프로세스가 종료된 상태이다. 사용하던 모든 데이터가 정리된다. 정상 종료인 exit와 비정상 종료인 abort를 포함한다.(메모리 삭제, 프로세스 제어 블록 삭제)

54. 실행상태(running status)  
실행 상태는 프로세스가 CPU를 할당받아 실행되는 상태이다. 준비 상태에 있는 많은 프로세스 중 실행 상태에 들어가는 프로세스는 CPU의 개수 만큼이다. 실행 상태에 있는 프로세스는 자신에게 주어진 시간, 즉 타임 슬라이스 동안만 작업할 수 있다. 그 시간을 다 사용하면 timeout(PID)가 실행된다. Timeout(PID)는 프로세스 제어 블록을 실행 상태에서 준비 상태로 옮긴다. 만약 실행 상태 동안 작업이 완료되면 exit(PID)가 실행되어 프로세스가 정상 종료된다.

55. 보류 상태(suspend status)  
보류 상태는 프로세스가 메모리에서 잠시 쫓겨난 상태로 휴식 상태와 차이가 있따. 보류 상태는 ‘일시 정지 상태’라고도 불리며, 보류 상태와 비교하여 일반적인 프로세스 상태를 활성 상태라고 한다. 프로세스는 다음과 같은 경우에 보류 상태가 된다.
- 메모리가 꽉 차서 일부 프로세스를 메모리 밖으로 내보낼 때
- 프로그램에 오류가 있어서 실행을 미루어야 할 때
- 바이러스와 같이 악의적인 공격을 하는 프로세스라고 판단될 때
- 매우 긴 주기로 반복되는 프로세스라 메모리 밖으로 쫓아내도 큰 문제가 없을 때
- 입출력을 기다리는 프로세스의 입출력이 계속 지연될 때

56. 보류 상태와 휴식 상태를 구분하자면, 보류 상태는 스왑 영역에 있는 상태이고 휴식 상태는 프로세스가 메모리에 있으나 멈춘 상태이다.

### 2. 프로세스 제어 블록과 문맥 교환
57. 프로세스 제어 블록(PCB)  
프로세스 제어블록은 프로세스를 실행하는 데 필요한 중요한 정보를 보관하는 자료 구조로 TCB(Task Control Block)라고도 한다. 모든 프로세스는 고유의 프로세스 제어 블록을 가지며, 프로세스 제어 블록은 프로세스 생성 시 만들어져서 프로세스가 실행을 완료하면 폐기된다.

58. 문맥 교환(Context Switching)은 CPU를 차지하던 프로세스가 나가고 새로운 프로세스를 받아들이는 작업을 말한다. 이때 두 프로세스 제어 블록의 내용이 변경된다.

59. 문맥 교환이 일어나는 경우는 매우 다양하다. 일반적으로 한 프로세스가 자신에게 주어진 시간을 다 사용하면 발생하고, 인터럽트가 걸렸을 때도 발생한다. 예를 들어 어떤 프로세스가 자신에게 주어진 메모리 공간을 넘어가려 한다면 이는 경계 레지스터의 범위를 벗어나는 것이다. 이때 인터럽트가 발생하여 현재 실행 중인 프로세스의 제어 블록을 저장한 후 인터럽트 관리 프로세스를 실행 상태로 만든다. 인터럽트 관리 프로세스는 메모리 범위를 넘어선 프로세스를 강제로 종료하고 인터럽트 처리를 마치는데, 이와 같이 인터럽트 처리를 할 때도 문맥 교환이 일어난다.

### 3. 프로세스의 연산
60. 프로세스의 구조  
- 코드 영역(code area)  
코드 영역은 프로그램의 본문이 기술된 곳으로 텍스트 영역(text area)이라고도 한다. 프로그래머가 작성한 프로그램은 코드 영역에 탑재되며 탑재된 코드는 읽기 전용으로 처리된다. 자기 자신을 수정하는 프로그램은 존재하지 않기 때문이다.
- 데이터 영역(data area)  
데이터 영역은 코드가 실행되면서 사용하는 변수나 파일 등의 각종 데이터를 모아놓은 곳이다. 데이터는 변하는 값이기 때문에 이곳의 내용은 기본적으로 읽기와 쓰기가 가능하다. 물론 상수로 선언된 변수는 읽기 전용이지만 대부분의 변수는 읽기와 쓰기가 가능하다.
- 스택 영역(stack area)  
스택 영역은 운영체제가 프로세스를 실행하기 위해 부수적으로 필요한 데이터를 모아놓은 곳이다. 예를 들어 프로세스 내에서 함수를 호출하면(function call) 함수를 수행하고 원래 프로그램으로 되돌아올 위치를 이 영역에 저장한다. 스택 영역은 운영체제가 사용자의 프로세스를 작동하기 위해 유지하는 영역이므로 사용자에게는 보이지 않는다.

61. fork() 시스템 호출  
fork() 시스템 호출은 실행 중인 프로세스를 복사하는 함수이다. 이때 실행하던 프로세스는 부모 프로세스, 새로 생긴 프로세스는 자식 프로세스로서 부모-자식 관계가 된다.

62. fork() 시스템 호출의 장점  
프로세스를 새로 만들지 않고 fork() 시스템 호출로 프로세스를 복사하면 다음과 같은 장점이 있다.
- 프로세스의 생성 속도가 빠르다.  
하드디스크로부터 프로그램을 새로 가져오지 않고 기존 메모리에서 복사하기 때문에 자식 프로세스의 생성 속도가 빠르다. 워드프로세서 프로그램을 2개 실행했을 때 첫 번째 것보다 두 번째 것의 실행 속도가 더 빠른 것을 경험해보았을 것이다.
- 추가 작업 없이 자원을 상속할 수 있다.  
부모 프로세서가 사용하던 모든 자원을 추가 작업 없이 자식 프로세스에 상속할 수 있다. 예를 들어 부모 프로세스가 파일 A를 사용하기 위해 초기화했다면 자식 프로세스는 파일 A를 바로 사용할 수 있다.
- 시스템 관리를 효율적으로 할 수 있다.  
부모 프로세스와 자식 프로세스가 자식 프로세스 구분자와 부모 프로세스 구분자로 연결되어 있기 때문에, 자식 프로세스를 종료하면 자식이 사용하던 자원을 부모 프로세스가 정리할 수 있다. 프로세스를 종료하면 프로세스가 사용하던 메모리 영역, 파일, 하드웨어를 잘 정리해야 하는데, 이러한 정리를 부모 프로세스에 맡김으로써 시스템이 효율적으로 관리 되는 것이다.

63. exec(): 프로세스는 그대로 둔 채 내용만 바꾸는 시스템 호출이다. exec() 시스템 호출을 하면 현재의 프로세스가 완전히 다른 프로세스로 전환된다.

64. exec() 시스템 호출을 사용하는 목적은 프로세스의 구조체를 재활용하기 위함이다. 새로운 프로세스를 만들려면 프로세스 제어 블록을 만들고 메모리의 자리를 확보하는 과정이 필요하다. 또한 프로세스를 종료한 후 사용한 메모리를 청소(garbage collection)하기 위해 상위 프로세스와 부모-자식 관계를 만들어야 한다. 이때 exec() 시스템 호출을 사용하면 이미 만들어진 프로세스 제어 블록, 메모리 영역, 부모-자식 관계를 그대로 사용할 수 있어 편리하다. 새로운 코드 영역만 가져오면 되기 때문에 운영체제의 작업이 수월하다.

65. 프로세스를 계층 구조로 만들면 프로세스 간의 책임 관계가 분명해져서 시스템을 관리하기가 수월하다. 프로세스가 작업을 마쳐서 그 프로세스가 사용하던 자원을 회수(garbage collection)할 때 특히 편리하다. 만약 모든 프로세스가 독립적으로 만들어지면 프로세스가 종료될 때마다 운영체제가 직접 자원을 회수해야 하기 때문에 작업이 복잡해질 것이다. 그러나 모든 프로세스를 부모-자식 관계로 만들면 자식 프로세스가 작업을 마쳤을 때 사용하던 자원을 부모 프로세스가 회수하면 된다.

### 4. 스레드
66. 프로세스는 요리 작업 전체와 같고, 스레드는 요리를 완성하기 위해 수행하는 각각의 조리에 해당하는 것이다.

67. 운영체제는 코드와 데이터를 메모리에 가져오고, 프로세스 제어 블록을 생성하고, 작업에 필요한 메모리 영역을 확보한 후, 준비된 프로세스를 준비 큐에 삽입한다. 프로세스가 생성되면 CPU 스케줄러는 프로세스가 해야 할 일을 CPU에 전달하고 실제 작업은 CPU가 수행한다. 이때 CPU 스케줄러가 CPU에 전달하는 일 하나가 스레드이다. 그러므로 CPU가 처리하는 작업의 단위는 프로세스로부터 전달받은 스레드이다. 그러므로 CPU가 처리하는 작업의 단위는 프로세스로부터 전달받은 스레드이다. 운영체제 입장에서의 작업 단위는 프로세스이고 CPU 입장에서의 작업 단위는 스레드인 것이다. 프로세스 입장에서는 스레드를 다음과 같이 정의할 수 있다.

68. 스레드  
프로세스의 코드에 정의된 절차에 따라 CPU에 작업 요청을 하는 실행 단위이다.

69. 작업의 크기  
작업을 상대적인 크기순으로 나열하면 job > task > operation이고, 이를 프로세스와 스레드의 관계에 대입하면 처리(job) > 프로세스(task) >스레드(operation)가 된다. 여러 개의 스레드가 모여 프로세스를 이루고 여러 개의 프로세스가 모여 처리가 되며, 여러 개의 프로세스를 모아서 한꺼번에 처리하는 방법을 일괄 작업(batch job)이라고 한다.

70. 개개의 프로세스와 스레드는 서로서로 미치는 영향이 다르다. 프로세스끼리는 약하게 연결되어 있는 반면 스레드끼리는 강하게 연결되어 있다.

71. 멀티태스크  
워드프로세서와 프린터 스풀러는 서로 독립적으로 작동하다가 필요할 때 출력하 데이터를 주고받는다. 서로 독립적이라는 것은 워드프로세서가 비정상적으로 종료되어도 프린터 스풀러는 정상적으로 작동한다는 의미이다. 이렇게 서로 독립적인 프로세스는 데이터를 주고받을 때 프로세스 간 통신(Inter Process Communication, IPC)을 이용한다.

72. 멀티스레드  
워드프로세서 프로세스 내의 문서 편집, 문서 입출력, 맞춤법 검사, 그림판 같은 스레드들이 동시에 작업을 하는 멀티스레드를 나타낸 것이다. 이러한 스레드들은 강하게 연결되어 있으므로 워드프로세서가 종료되면 프로세스 내의 스레드도 강제 종료된다. 멀티스레드는 변수나 파일 등을 공유하고 전역 변수나 함수 호출 등의 방법으로 스레드 간 통신을 한다.

73. 멀티스레드  
운영체제가 소프트웨어적으로 프로세스를 작은 단위의 스레드로 분할하여 운영하는 기법이다.

74. CPU 멀티스레드  
하드웨어적인 방법으로 하나의 CPU에서 여러 스레드를 동시에 처리하는 병렬 처리 기법이다.

75. 커널 스레드  
커널이 직접 생성하고 관리하는 스레드이다.

76. 사용자 스레드  
라이브러리에 의해 구현된 일반적인 스레드이다.
 
### 5. 동적 할당 영역과 시스템 호출
77. 자식의 자원을 정리해야 할 부모 프로세스가 먼저 종료되면 자식 프로세스의 exit() 함수는 돌아갈 곳이 없는데 이러한 프로세스가 바로 미아 프로세스(Orphan Process)이다. 물론 반환되지 못한 자원은 나중에 운영체제의 자원 회수로 처리되겠지만, 미아 프로세스가 많이 발생하면 시스템의 자원이 낭비된다.

# Chapter 4. CPU 스케줄링
### 1. 스케줄링의 개요
 
77. 고수준 스케줄링  
고수준 스케줄링에서는 전체 시스템의 부하를 고려하여 작업을 시작할지 말지를 결정한다. 이 결정에 따라 시스템의 전체 프로세스 수가 결정되는데 이를 멀티프로그래밍 정도(degree of multiprogramming)라고 한다. 고수준 스케줄링은 메인프레임과 같은 큰 시스템에서 규모가 큰 일괄 작업을 처리할 때 사용된다.
 
78. 중간 수준 스케줄링  
시스템의 부하를 조절하려면 고수준 스케줄링 대신 중간 수준 스케줄링을 고려해야 한다. 시스템에 과부하가 걸려서 전체 프로세스 수를 조절해야 한다면 이미 활성화된 프로세스 중 일부를 보류 상태로 보낸다. 보류된 프로세스는 처리 능력에 여유가 생기면 다시 활성화 된다.
 
79. 저수준 스케줄링  
저수준 스케줄링에서는 실제로 작업이 이루어진다. 오늘날의 CPU 스케줄러는 대부분 중간 수준 스케줄링과 저수준 스케줄링으로 구성되어 있다.
 
80. CPU 스케줄링의 목적  
- 공평성 : 모든 프로세스가 자원을 공평하게 배정받아야 하며, 자원 배정 과정에서 특정 프로세스가 배제되어서는 안 된다.
- 효율성 : 시스템 자원의 유휴 시간 없이 사용되도록 스케줄링을 하고, 유휴 자원을 사용하려는 프로세스에는 우선권을 주어야 한다.
- 안정성 : 우선순위를 사용하여 중요 프로세스가 먼저 작동하도록 배정함으로써 시스템 자원을 점유하거나 파괴하련느 프로세스로부터 자원을 보호해야 한다.
- 확장성 : 프로세스가 증가해도 시스템이 안정적으로 작동하도록 조치해야 한다. 또한 시스템 자원이 늘어나는 경우 이혜택이 시스템에 반영되게 해야 한다.
- 반응 시간 보장 : 응답이 없는 경우 사용자는 시스템이 멈춘 것으로 가정하기 때문에 시스템은 적절한 시간 안에 프로세스의 요구에 반응해야 한다.
- 무한 연기 방지 : 특정 프로세스의 작업이 무한히 연기되어서는 안 된다.

### 2. 스케줄링 시 고려 사항
81. 선점형 스케줄링(preemptive scheduling)  
어떤 프로세스가 CPU를 할당받아 실행 중이더라도 운영체제가 CPU를 강제로 빼앗을 수 있는 스케줄링 방식이다.
 
82. 비선점형 스케줄링(non-preemptive scheduling)  
어떤 프로세스가 CPU를 점유하면 다른 프로세스가 이를 빼앗을 수 없는 스케줄링 방식이다.
 
83. 시스템에는 다양한 우선순위의 프로세스가 공존하며, 우선순위가 높은 프로세스가 CPU를 먼저, 더 오래 차지하게 된다.
 
84. CPU를 할당받아 실행하는 작업을 CPU 버스트(CPU burst), 입출력 잡업을 입출력 버스트(I/O burst)라고 부른다.
 
85. CPU 집중 프로세스(CPU bound process)  
수학 연산과 같이 CPU를 많이 사용하는 프로세스를 말한다. 즉 CPU 버스트가 많은 프로세스이다.
 
86. 입출력 집중 프로세스(I/O bound process)  
저장장치에서 데이터를 복사하는 일과 같이 입출력을 askg이 사용하는 프로세스를 말한다. 즉 입출력 버스트가 많은 프로세스이다.
 
87. 전면 프로세스  
GUI를 사용하는 운영체제에서 화면의 맨 앞에 놓인 프로세스를 말한다. 현재 입력과 출력을 사용하는 프로세스이며, 사용자와 상호작용이 가능하여 상호작용 프로세스라고도 한다.
 
88. 후면 프로세스  
사용자와 상호작용이 없는 프로세스이다. 압축 프로그램처럼 사용자의 입력 없이 작동하기 때문에 일괄 작업 프로세스라고도 한다.
 
### 3. 다중 큐
89. 준비 상태의 다중 큐와 대기 상태의 다중 큐는 차이가 있다. 준비 큐는 한 번에 하나의 프로세스를 꺼내어 CPU를 할당하는 반면, 대기 큐는 여러 개의 프로세스 제어 블록을 동시에 꺼내어 준비 상태로 옮긴다. 시스템에는 많은 입출력장치가 있기 때문에 입출력이 동시에 끝날 경우 여러 개의 인터럽트가 한꺼번에 처리된다. 이렇게 동시에 끝나는 인터럽트를 처리하기 위해 인터럽트 벡터(interrupt vector)라는 자료 구조를 사용한다. 인터럽트 벡터에는 동시에 완료된 입출력 정보와 처리 방법이 담겨 있는데, 이 정보에 따라 완료된 프로세스 제어 블록은 모두 준비 상태로 이동한다.
 
### 4. 스케줄링 알고리즘
90. 
- 대기 시간 : 프로세스가 생성된 후 실행되기 전까지 대기하는 시간
- 응답 시간 : 첫 작업을 시작한 후 첫 번째 출력(반응)이 나오기까지의 시간
- 실행 시간 : 프로세스 작업이 시작된 후 종료되기까지의 시간
- 반환 시간 : 대기 시간을 포함하여 실행이 종료될 때까지의 시간
 
91. FCFS(First Come First Served)  
FCFS 스케줄링은 준비 큐에 도착한 순서대로 CPU를 할당하는 비선점형 방식으로, 선입선출 스케줄링이라고도 한다.
 
92. SJF(Shortest Job First)  
SJF 스케줄링은 준비 큐에 있는 프로세스 중에서 실행 시간이 가장 짧은 작업부터 CPU를 할당하는 비선점형 방식으로, 최단 작업 우선 스케줄링이라고도 한다.
 
93. 현대 운영체제에서는 프로세스의 작업 길이(시간)을 추정하는 것이 어렵기 때문에 SJF 스케줄링을 사용하기가 힘들다. … SJF 스케줄링은 공평성을 위배하는 문제가 있다.
 
94. HRN(Highest Response Ratio Next)  
HRN 스케줄링은 SJF 스케줄링에서 발생할 수 있는 아사 현상을 해결하기 위해 만들어진 비선점형 알고리즘으로, 최고 응답률 우선 스케줄링이라고도 한다. SJF 스케줄링은 프로세스의 실행 시간이 판단 기준이기 때문에 항상 적은 시간을 사용하는 프로세스에 우선권이 주어지지만, HRN 스케줄링은 서비스를 받기 위해 기다린 시간과 CPU 사용 시간을 고려하여 스케줄링을 하는 방식이다. HRN 스케줄링에서 프로세스의 우선순위를 결정하는 기준은 다음과 같다.
 
우선 순위 = (대기 시간 + CPU 사용 시간) / CPU 사용 시간

95. 라운드 로빈 스케줄링(Round Robin, RR)  
‘순환 순서 방식’으로 번역되는 라운드 로빈 스케줄링은 한 프로세스가 할당받은 시간(타임 슬라이스) 동안 작업을 하다가 작업을 완료하지 못하면 준비 큐의 맨 뒤로 가서 자기 차례를 기다리는 방식이다. 선점형 알고리즘 중 가장 단순하고 대표적인 방식으로, 프로세스들이 작업을 완료할 때까지 계속 순환하면서 실행된다.
 
96. 타임 슬라이스가 큰 경우  
타임 슬라이스 1,000밀리초인 시스템에서 비디오 플레이어와 워드 프로세서가 동시에 실행된다고 가정해보자. 비디오 플레이어 1초, 워드프로세서 1초씩 두 프로그램이 1초 간격으로 실행되어 비디오가 끊겨 보이고 워드프로세서의 반응 속도가 매우 느릴 것이다.
 
97. 타임 슬라이스가 작은 경우  
타임 슬라이스를 1밀리초와 같이 매우 작은 값으로 설정하면 사용자는 여러 프로그램이 동시에 실행되는 것처럼 느낄 것이다. 그러나 타임 슬라이스를 너무 작게 설정하면 시스템의 전반적인 성능이 떨어진다. 문맥 교환이 너무 자주 일어나 문맥 교환에 걸리는 시간이 실제 작업 시간보다 상대적으로 커지며, 문맥 교환에 많은 시간을 낭비하여 실제 작업을 못하는 문제가 발생한다.
 
98. 결론적으로 타임 슬라이스는 되도록 작게 설정하되 문맥 교환에 걸리는 시간을 고려하여 적당한 크기로 하는 것이 중요하다. 참고로 유닉스 운영체제에서는 타임 슬라이스가 대략 100밀리초이다. 대략이라고 하는 이유는 타임 슬라이스를 고정하지 않고 10~200밀리초 사이에서 조정할 수 있도록 했기 때문이다.
 
99. SRT(Shortest Remaining Time)  
SRT 스케줄링은 SJF 스케줄링과 라운드 로빈 스케줄링을 혼합한 방식으로, 최소 잔류 시간 우선 스케줄링이라고도 한다. 쉽게 말해 SJF 스케줄링의 선점형 버전이라고 할 수 있다. SRT 스케줄링은 기본적으로 라운드 로빈 스케줄링을 사용하지만, CPU를 할당받을 프로세스를 선택할 때 남아 있는 작업 시간이 가장 적은 프로세스를 선택한다. 라운드 로빈 스케줄링이 큐에 있는 순서대로 CPU를 할당한다면, SRT 스케줄링은 남은 시간이 적은 프로세스에 CPU를 먼저 할당한다.
 
100. SRT 스케줄링의 평가  
SJF 스케줄링과 SRT 스케줄링의 평균 대기 시간을 비교해보면 SRT 스케줄링의 평균 대기 시간이 짧다. 하지만 SRT 스케줄링은 좋은 알고리즘이 아니다. 현재 실행 중인 프로세스와 큐에 있는 프로세스의 남은 시간을 주기적으로 계산하고, 남은 시간이 더 적은 프로세스와 문맥 교환을 해야 하므로 SJF 스케줄링에는 없는 작업이 추가된다. 또한 SRT 스케줄리은 SJF 스케줄링과 마찬가지로 운영체제가 프로세스의 종료 시간을 예측하기 어렵고 아사 현상이 일어나기 때문에 잘 사용하지 않는다.
 
101. 우선순위 스케줄링의 동작 방식  
프로세스는 중요도에 따라 우선순위를 갖는데 이러한 우선순위를 반영한 스케줄링 알고리즘이 우선순위 스케줄링이다. 우선순위 스케줄링은 어떤 기준으로 우선순위를 정하느냐에 따라 다양하게 구현할 수 있다.
 
102. 다단계 큐(multilevel queue) 스케줄링  
다단계 큐 스케줄링은 우선순위에 따라 준비 큐를 여러 개 사용하는 방식이다.
 
103. 다단계 피드백 큐(multilevel feedback queue) 스케줄링  
다단계 피드백 큐 스케줄링은 우선순위가 낮은 프로세스에 불리한 다단계 큐 스케줄링의 문제점을 보완한 방식이다. 다단계 피드백 큐 스케줄링은 다단계 큐 스케줄링과 기본적인 형태가 같아 우선순위를 가진 여러 개의 큐를 사용한다. 하지만 다단계 큐 스케줄링의 경우 각 단계의 큐에 라운드 로빈 방식을 사용하고 우선순위에는 변화가 없는 데 반해, 다단계 피드백 큐 스케줄링의 경우 CPU를 사용하고 난 프로세스의 우선순위가 낮아진다. CPU를 사용하고 난 프로세스는 원래의 큐로 되돌아가지 않고 우선순위가 하나 낮은 큐의 끝으로 들어간다.
 
104. 프로세스의 우선순위가 낮아질수록 해당 큐의 타임 슬라이스가 커진다. 다단계 피드백 큐 스케줄링은 우선순위가 낮은 프로세스의 실행 기회를 확대하려고 하지만, 그렇다고 해도 우선순위가 낮은 프로세스가 우선순위가 높은 프로세스보다 CPU를 얻을 확률이 여전히 낮다. 따라서 어렵게 얻은 CPU를 좀 더 오랫동안 사용할 수 있도록 우선순위가 낮은 큐의 타임 슬라이스를 크게 설정한다.
 
105. 다단계 피드백 큐 스케줄링은 오늘날의 운영체제가 CPU 스케줄링을 위해 일반적으로 사용하는 방식으로, 변동 우선순위 알고리즘의 전형적인 예이다. 유닉스 운영체제에서 타임 슬라이스를 고정하지 않고 10~200밀리초 사이에서 조장할 수 있도록 한 이유는 바로 다단계 피드백 큐 스케줄링을 사용하기 때문이다.
 
### 5. 인터럽트 처리
106. 하지만 다양한 입출력장치가 개발되어 운영체제가 모든 입출력을 관리하기 어려워지자 이벤트 드리븐 방식과 마찬가지로 입출력을 요청하고 입출력이 완료되면 이벤트를 발생시켜 이 사실을 알리게 되었는데 이를 인터럽트라고 한다.
 
107. 동기적 인터럽트의 종류  
- 프로그램상의 문제 때문에 발생하는 인터럽트(예 : 다른 사용자의 메모리 영역에 접근하는 경우, 오버플로나 언더플로에 의해 발생하는 경우 등)
- 컴퓨터 작업자가 의도적으로 프로세스를 중단하기 위해 발생시킨 인터럽트(예 : Ctrl + C)
- 입출력장치 같은 주변장치의 조작에 의한 인터럽트
- 산술 연산 중 발생하는 인터럽트(예 : 어떤 수를 0으로 나눔)
 
108. 비동기적 인터럽트는 하드디스크 읽기 오류, 메모리 불량과 같은 하드웨어적인 오류로 발생하는 인터럽트로, 사용자가 직접 작동하는 키보드 인터럽트, 마우스 인터럽트 등이 있다.

109. 인터럽트 처리 과정  
1) 인터럽트가 발생하면 현재 실행 중인 프로세스는 일시 정지 상태가 되며, 재시작하기 위해 현재 프로세스 관련 정보를 임시로 저장한다.
2) 인터럽트 컨트롤러가 실행되어 인터럽트의 처리 순서를 결정한다. 이때 여러 개의 인터럽트가 동시에 발생했다면 인터럽트의 우선순위를 고려하여 중요한 인터럽트부터 처리하도록 순서를 결정한다.
3) 먼저 처리할 인터럽트가 결정되면 인터럽트 벡터에 등록된 인터럽트 핸들러가 실행된다. 인터럽트 핸들러는 인터럽트 처리를 위해 미리 정의된 함수이고, 인터럽트 벡터는 인터럽트와 인터럽트 핸들러를 일대일로 연결한 자료 구조이다. 인터럽트 처리를 위한 함수를 정의하여 인터럽트 벡터에 등록해놓으면 해당 인터럽트 발생 시 함수가 실행되어 인터럽트를 처리한다.
4) 인터럽트 벡터에 연결된 핸들러가 인터럽트 처리를 마치면 일시 정지된 프로세스가 다시 실행되거나 종료된다. 발생한 인터럽트가 입출력 완료 같은 경우이면 일시 정지된 프로세스가 다시 실행되고, 다른 프로세스 메모리 영역 침범이나 오류 같은 경우이면 종료된다.
 
110. 사용자가 커널 모드로 진입하는 경우는 두 가지이다. 첫째, 시스템 호출을 사용한 경우, 둘째, 인터럽트를 발생시킨 경우이다. 시스템 호출에 의해 커널 모드로 진입하는 것은 자신이 원해서 진입하는 것이기 때문에 자발적(voluntary)이지만 인터럽트에 의해 커널 모드로 진입하는 것은 비자발적(non-voluntary)이다. 어떤 프로세스가 인터럽트를 발생시켰다는 것은 잘못된 명령을 수행하여 동기적 인터럽트가 발생한 것이므로 프로세스가 강제 종료된다. 그러므로 사용자 프로세스가 자발적으로 커널 모드에 진입할 수 있는 유일한 수단은 시스템 호출이다.
 
# Chapter 5. 프로세스 동기화
### 1. 프로세스 간 통신
111. 프로세스는 시스템 내에서 독립적으로 실행되기도 하고 데이터를 주고받으며 협업하기도 한다. 프로세스가 다른 프로세스와 데이터를 주고받는 프로세스간 통신(IPC)에는 같은 컴퓨터 내에 있는 프로세스뿐만 아니라 네트워크로 연결된 다른 컴퓨터에 있는 프로세스와의 통신도 포함된다.

112. 전역 변수나 파일을 사용하여 통신하는 것은 운영체제의 도움 없이 진행되는 통신 방식이며 파이프, 소켓, 원격 프로시저 호출(Remote Procedure Call, RPC)은 운영체제가 제공하는 통신 방식이다.

113. 
- 프로세스 내부 데이터 통신 : 하나의 프로세스 내에 2개 이상의 스레드가 존재하는 경우의 통신이다. 프로세스 내부의 스레드는 전역 변수나 파일을 이용하여 데이터를 주고받는다.
- 프로세스 간 데이터 통신 : 같은 컴퓨터에 있는 여러 프로세스끼리 통신하는 경우로. 공용 파일 또는 운영체제가 제공하는 파이프를 사용하여 통신한다.
- 네트워크를 이용한 데이터 통신 : 여러 컴퓨터가 네트워크로 연결되어 있을 때도 통신이 가능한데, 이 경우 프로세스는 소켓을 이용하여 데이터를 주고받는다. 이처럼 소켓을 이용하는 프로세스 간 통신을 네트워킹이라고 한다. 다른 컴퓨터에 있는 함수를 호출하여 통신하는 원격 프로시저 호출도 여기에 해당한다.

114. 파일을 이용한 통신은 부모-자식 관계 프로세스 간 통신에 많이 사용되며 운영체제가 프로세스 동기화를 제공하지 않는다. 그래서 프로세스가 알아서 동기화를 해야 하는데 주로 부모 프로세스가 wait() 함수를 이용하여 자식 프로세스의 작업이 끝날 때까지 기다렸다가 작업을 시작한다.

115. 파이프를 이용한 통신  
프로세스 동기화 문제를 해결하는 방법으로 파이프가 있다. 파이프는 운영체제가 제공하는 동기화 통신 방식으로, 파일 입출력과 같이 open() 함수로 기술자를 얻고 작업을 한 후 close() 함수로 마무리한다. 파이프를 이용한 통신은 전역 변수를 이용한 통신과 마찬가지로 단방향 통신이다. 파이프로 양방향 통신을 하려면 파이프 2개를 사용해야 한다.

116. 소켓을 이용한 통신  
여러 컴퓨터에 있는 프로세스끼리도 통신을 할 수 있다. 여러 컴퓨터에 있는 프로세스 간 통신은 네트워킹이라고 한다. 네트워킹 상황에서의 통신은 원격 프로시저 호출이나 소켓을 이용한다. 프로시저 호출이 한 컴퓨터에 있는 함수를 호출하는 것이라면, 원격 프로시저 호출은 다른 컴퓨터에 있는 함수를 호출하는 것이다. 자바 같은 객체지향 언어에서 다른 컴퓨터에 있는 객체의 메소드를 불러와 사용하는 것은 모두 원격 프로시저 호출의 예이다.

117. 네트워크 프로그래밍을 흔히 소켓 프로그래밍이라고 부르는 이유는 네트워킹의 기본이 소켓이기 때문이다.

### 2. 공유 자원과 임계구역
118. 임계구역에서는 프로세스들이 동시에 작업하면 안 된다. 어떤 프로세스가 임계구역에 들어가면 다른 프로세스는 임계구역 밖에서 기다려야 하며 임계구역의 프로세스가 나와야 들어갈 수 있다.

119. 임계구역 문제를 해결하는 방법은 다음의 세 가지 조건을 만족해야 한다.  
- 상호 배제(mutual exclusion)
한 프로세스가 임계구역에 들어가면 다른 프로세스는 임계구역에 들어갈 수 없다.
- 한정 대기(bounded waiting)
한 요리사가 믹서를 계속 사용하여 다른 요리사가 믹서를 사용하지 못한 채 계속 기다리면 안 되는 것처럼 어떤 프로세스도 무한 대기(infinite postpone)하지 않아야 한다. 즉 특정 프로세스가 임계구역에 진입하지 못하면 안 된다.
- 진행의 융통성(progress flexibility)
진행의 융통성은 한 프로세스가 다른 프로세스의 진행을 방해해서는 안 된다는 것을 의미한다.

### 3. 임계구역 해결 방법
120. 피터슨 알고리즘, 데커 알고리즘, 세마포어, 모니터

### 4. 파일, 파이프, 소켓 프로그래밍
121. 파일 내의 데이터는 한 줄로 길게 저장되는데 이러한 파일을 순차 파일(sequential file)이라 하고, 순차 파일에 접근하는 방식을 순차적 접근(sequential access)이라 한다. 순차적 접근의 대표적인 예로는 카세트테이프를 들 수 있다.

# Chapter 6. 교착 상태
### 1. 교착 상태의 개요
### 2. 교착 상태 필요조건
122. 교착 상태는 상호 배제, 비선점, 점유와 대기, 원형 대기를 모두 충족해야 발생한다. 이 중 단 하나라도 충족하지 않으면 교착상태가 발생하지 않는다.
- 상호 배제(mutual exclusion)
한 프로세스가 사용하는 자원은 다른 프로세스와 공유할 수 없는 배타적인 자원이어야 한다. 배타적인 자원은 임계구역으로 보호되기 때문에 다른 프로세스가 동시에 사용할 수 없다. 따라서 배타적인 자원을 사용하면 교착 상태가 발생한다.
- 비선점(non-preemption)
한 프로세스가 사용 중인 자원은 중간에 다른 프로세스가 빼앗을 수 없는 비선점 자원이어야 한다. 어떤 자원을 빼앗을 수 있다면 시간 간격을 두고 자원을 공유할 수 있다. 하지만 자원을 빼앗을 수 없으면 공유할 수도 없으므로 교착 상태가 발생한다.
- 점유와 대기(hold and wait)
프로세스가 어떤 자원을 할당받은 상태에서 다른 자원을 기다리는 상태여야 한다. 다른 프로세스의 작업 진행을 방해하는 교착 상태가 발생하려면 다른 프로세스가 필요로 하는 자원을 점유하고 있으면서 또 다른 자원을 기다리는 상태가 되어야 한다.
- 원형 대기(circular wait)
점유와 대기를 하는 프로세스 간의 관계가 원을 이루어야 한다. 프로세스가 특정 자원에 대해 점유와 대기를 한다고 해서 모두 교착 상태에 빠지는 것은 아니다. 점유와 대기를 하는 프로세스들이 서로 방해하는 방향이 원을 이루면 프로세스들이 서로 양보하지 않기 때문에 교착 상태에 빠진다.

### 3. 교착 상태 해결 방법
123. 교착 상태 예방  
교착 상태를 유발하는 네 가지 조건이 발생하지 않도록 무력화하는 방식이다.

124. 교착 상태 회피  
자원 할당량을 조절하여 교착 상태를 해결하는 방식이다.

125. 교착 상태 검출과 회복  
교착 상태 검출은 어떤 제약을 가하지 않고 자원 할당 그래프를 모니터링하면서 교착 상태가 발생하는지 살펴보는 방식이다.

126. 교착 상태 회피의 문제점
- 프로세스가 자신이 사용할 모든 자원을 미리 선언해야 한다.
- 시스템의 전체 자원 수가 고정적이어야 한다.
- 자원이 낭비된다.

127. 교착 상태 검출의 개념  
교착 상태 예방은 실제로 구현하기 어렵고, 교착 상태 회피는 구현할 수는 있지만 자원을 낭비하는 문제가 있다. 따라서 교착 상태 해결 방법 중 가장 현실적인 것은 바로 교착 상태 검출이다. 교착 상태 검출은 운영체제가 프로세스의 작업을 관찰하면서 교착 상태 발생 여부를 계속 주시하는 방식이다. 만약 교착 상태가 발견되면 이를 해결하기 위해 교착 상태 회복 단계를 밟는다.
교착 상태 검출은 타임아웃을 이용하는 방법과 자원 할당 그래프를 이용하는 방법이 있다.

128. 타임아웃을 이요한 교착 상태 검출  
타임아웃을 이용한 교착 상태 검출은 일정 시간 동안 적업이 진행되지 않은 프로세스를 교착 상태가 발생한 것으로 간주하여 처리하는 방법이다. 교착 상태가 자주 발생하지 않을 것이라는 가정하에 사용하는 것으로, 특별한 알고리즘이 없어 쉽게 구현할 수 있다. 그런데 이 방법은 다음과 같은 문제가 있다. 
- 엉뚱한 프로세스가 강제 종료될 수 있다.
- 모든 시스템에 적용할 수 없다.

129. 자원 할당 그래프를 이용한 교착 상태 검출
교착 상태를 검출하는 또 다른 방법은 자원 할당 그래프를 이용하는 것이다.

### 4. 다중 자원과 교착 상태 검출
130. 다중 자원의 경우 사이클이 있다고 해서 모두 교착 상태가 되는 것은 아니다. 다중 자원이 포함된 자원 할당 그래프에서는 대기 그래프와 그래프 감소 방법을 이용하여 사이클을 찾는다.

131. 대기 그래프(wait for graph)는 자원 할당 그래프에서 프로세스와 프로세스 간에 기다리는 관계만 나타낸 그래프이다. 그리고 그래프 감소(graph reduction)는 대기 그래프에서 작업이 끝날 가능성이 있는 프로세스의 화살표와 관련 프로세스의 화살표를 연속적으로 지워가는 작업을 말한다. 여기서 작업이 끝날 가능성이 있는 프로세스란 기다리는 자원이 없는 프로세스를 가리킨다. 이렇게 다중 자원이 있는 대기 그래프에서 그래프 감소를 완료한 후에도 사이클이 남아 있다면 교착 상태가 발생한 것으로 판단한다.

132. 결론적으로, 단일 자원만 있는 자원 할당 그래프에서는 사이클만으로 교착 상태 검출이 가능하지만, 다중 자원을 사용할 때는 그래프 감소를 한 후 사이클이 남아 있는지 확인하여 교착 상태를 검출한다.

# Part3. 메모리 관리
# Chapter 7. 물리 메모리 관리
### 1. 메모리 관리의 개요
133.  
- 컴파일러 : 소스코드를 컴퓨터가 실행할 수 있는 기계어로 번역한 후 한꺼번에 실행한다. C언어, 자바 등이 이 방식으로 프로그램을 실행한다.
- 인터프리터 : 소스코드를 한 행씩 번역하여 실행한다. 자바스크립트, 베이직 등이 이 방식으로 프로그램을 실행한다.

134. 컴파일러의 목적  
1) 오류 발견
2) 코드 최적화

135. 메모리 관리자의 역할  
메모리 관리는 메모리 관리자가 담당한다. 메모리 관리자는 정확히 말해 메모리 관리 유닛(Memory Manage Unit, MMU)이라는 하드웨어인데 일반적으로 메모리 관리자라고 일컫는다. 메모리 관리자의 작업은 가져오기(fetch), 배치(placement), 재배치(replacement)이다.

136. 가져오기 정책  
프로세스가 필요로 하는 데이터를 언제 메모리로 가져올지 결정하는 정책이다. 프로세스가 요청할 때 메모리로 가져오는 것이 일반적인 방법이지만, 필요하다고 예상되는 데이터를 미리 가져오는 방법(prefetch)도 있다.

137. 배치 정책  
가져온 프로세스를 메모리의 어떤 위치에 올려놓을지 결정하는 정책이다. 메모리를 같은 크기로 자르는 것을 페이징(paging)이라고 하며, 프로세스의 크기에 맞게 자르는 것을 세그먼테이션(segmentation)이라고 한다. 배치 정책은 페이징과 세그먼테이션의 장단점을 파악하여 메모리를 효율적으로 관리할 수 있도록 정책을 만드는 것이다. 이는 한정된 메모리를 효율적으로 사용하기 위한 것으로, 시스템의 효율을 좌우하는 매우 중요한 기준이다.

138. 페이징은 책의 모든 페이지가 같은 크기인 데에서 유래된 용어이다.

139. 재배치 정책  
메모리가 꽉 찼을 때 메모리 내에 있는 어떤 프로세스를 내보낼지 결정하는 정책이다. 앞으로 사용하지 않을 프로세스를 내보내면 시스템의 성능이 올라가지만 자주 사용할 프로세스를 내보내면 성능이 떨어진다. 앞으로 사용하지 않을 프로세스를 찾아서 내보내는 알고리즘을 교체 알고리즘(replacement algorithm)이라고 한다.

### 2. 메모리 주소
140. 상대 주소는 사용자 프로세스 입장에서 바라본 주소이며, 절대 주소와 관계없이 항상 0번지부터 시작한다. 상대 주소를 사용하면 프로세스 입장에서 상대 주소가 사용할 수 없는 영역의 위치를 알 필요가 없고, 주소가 항상 0번지부터 시작하기 때문에 편리하다.

141. 상대 주소는 사용자 프로세스 입장에서 운영체제가 어디서 끝나는지, 자신의 데이터가 어디에 존재하는지 알 필요 없이 주소 공간이 항상 0번지부터 시작하는데, 이러한 주소 공간을 논리 주소 공간이라고 부른다. 앞에서 설명했듯이 논리 주소 공간은 물리 주소 공간의 상대적인 개념이다. 즉 논리 주소 공간은 상대 주소를 사용하는 주소 공간이고, 물리 주소 공간은 절대 주소를 사용하는 주소 공간이다.

### 3. 단일 프로그래밍 환경에서의 메모리 할당
142. 실제 메모리보다 큰 프로그램도 이와 같은 방식으로 처리하면 된다. 프로그램의 크기가 실제 메모리(물리 메모리)보다 클 때 전체 프로그램이 메모리에 가져오는 대신 적당한 크기로 잘라서 가져오는 기법을 메모리 오버레이(memory overlay)라고 한다. ‘overlay’는 ‘겹겹이 쌓다’, ‘중첩시키다’라는 뜻으로, 메모리 오버레이는 하나의 메모리에 여러 프로그램을 겹겹이 쌓아놓고 실행하는 것을 말한다.

143. 메모리가 모자라서 쫓겨난 프로세스는 저장장치의 특별한 공간에 모아두는데 이러한 영역을 스왑 영역(swap area)이라고 부른다. 그리고 스왑 영역에서 메모리로 데이터를 가져오는 작업은 스왑인(swap in), 메모리에서 스왑 영역으로 데이터를 내보내는 작업은 스왑아웃(swap out)이라고 한다.

144. 스왑 영역은 메모리 관리자가 관리한다. 원래 하드디스크 같은 저장장치는 저장장치 관리자가 관리하지만, 스왑 영역은 메모리에서 쫓겨났다가 다시 돌아가는 데이터가 머무는 곳이기 때문에 저장장치는 장소만 빌려주고 메모리 관리자가 관리하는 것이다.

### 4. 다중 프로그래밍 환경에서의 메모리 할당
145. 메모리 분할 방식  
- 가변 분할 방식 : 프로세스의 크기에 따라 메모리를 나누는 것이다.
- 고정 분할 방식 : 프로세스의 크기와 상관없이 메모리를 같은 크기로 나누는 것이다.

146.  
- 가변 분할 방식 : 프로세스의 크기에 맞게 메모리가 분할되므로 메모리 영역이 각각 다르다(17KB~40KB). 한 프로세스가 연속된 공간에 배치되기 때문에 연속 메모리 할당(contiguous memory allocation)이라고 한다.
- 고정 분할 방식 : 프로세스의 크기에 상관없이 메모리가 같은 크기로 나뉘며, 큰 프로세스가 메모리에 올라오면 여러 조각으로 나뉘어 배치된다. 한 프로세스가 분산되어 배치되기 때문에 비연속 메모리 할당(noncontiguous memory allocation)이라고 한다.

147. 가변 분할 방식에서는 외부 단편화로 인한 문제를 해결하기 위해 메모리 배치 방식(memory placement strategy)이나 조각 모음(defragmentation)을 사용한다. 메모리 배치 방식은 작은 조각이 발생하지 않도록 프로세스를 배치하는 것이며, 조각 모음은 조각이 발생했을 때 작은 조각들을 모아서 하나의 큰 덩어리로 만드는 작업이다. 메모리 배치 방식은 가변 분할 방식에서 선처리에 해당하고 조각 모음은 후처리에 해당한다.

148. 가변 분할 방식의 외부 단편화 문제를 해결하기 위한 대표적인 메모리 배치 방식으로는 최초 배치(first fit), 최적 배치(best fit), 최악 배치(worst fit)가 있다. 이 외에도 버디 시스템(buddy system)이 있다.

149. 조각 모음은 서로 떨어져 있는 여러 개의 빈 공간을 합치는 작업이다.

150. 고정 분할 방식은 가변 분할 방식처럼 조각 모음을 할 필요가 없어 관리가 수월하므로 현대의 메모리 관리 시스템은 고정 분할 방식을 기본으로 사용하고 있다.

151. 버디 시스템의 특징  
버디 시스템은 가변 분할 방식과 고정 분할 방식의 특징을 모두 가지고 있다. 가변 분할 방식처럼 메모리가 프로세스 크기대로 나뉘며, 고정 분할 방식처럼 하나의 구역에 다른 프로세스가 들어갈 수 없고, 메모리의 한 구역 내부에 조각이 생겨 내부 단편화가 발생한다.

152. 효율적인 공간 관리 측면에서 보면 고정 분할 방식과 버디 시스템은 비슷한 수준이다. 그러나 공간을 1/2로 나누어가면서 메모리를 배분하는 버디 시스템보다 모든 공간을 똑 같은 크기로 나누는 고정 분할 방식이 메모리 관리 측면에서 단순하기 때문에 버디 시스템보다 고정 분할 방식이 많이 사용되고 있다.

### 5. 컴파일과 메모리 관리
153. char, int, float는 보관하려는 자료의 형태를 나타낼 뿐 아니라 사용하려는 메모리의 크기를 나타내기도 한다. 컴파일러마다 다르지만 보통의 경우 문자형(char)은 1B, 정수형(Int)은 4B, 실수형(float)은 8B를 사용한다. 따라서 컴파일러는 프로그래머가 지정한 자료형의 크기에 따라 메모리를 확보하고 그곳에 적당한 값을 집어넣는다. 모든 변수에 대해 메모리를 확보하고 오류를 찾기 위해 심벌 테이블을 유지한다.

154. 기억해야 할 점은 변수가 메모리 주소의 또 다른 이름이라는 것이다. 사실 기계어 입장에서는 변수를 알 필요가 없다. 기계어는 메모리 주소만 필요로 하는데도 변수를 사용하는 중요한 이유는 프로그래머가 주소값만으로 기억하기는 어렵기 때문이다.

155. 프로그램의 변수도 같은 역할을 한다. 사용자는 결국 메모리 주소를 사용하지만 주소만으로는 기억하기가 어렵기 때문에 각 주소에 대응하는 변수를 사용하는 것이다.

156. 이렇게 프로그래머가 변수를 사용하여 프로그램을 만들면 컴파일러는 모든 변수를 메모리 주소로 바꾸어 기계어로 된 실행 파일을 만든다. 결론적으로 컴파일러는 프로그래머가 만든 변수를 적당한 크기의 메모리 주소로 변환하여 기계어로 바꾸는 것이다.

# Chapter 8. 가상 메모리 기초
### 1. 가상 메모리 개요
157. 가상 메모리는 물리 메모리의 크기와 상관없이 프로세스에 커다란 메모리 공간을 제공하는 기술이다. 프로세스는 운영체제가 어디에 있는지, 물리 메모리의 크기가 어느정도 인지 신경 쓰지 않고 메모리를 마음대로 사용할 수 있다.

### 2. 페이징 기법
158. 페이지 테이블 매핑 방식  
시스템 내에는 여러 개의 프로세스가 존재하고, 각 프로세스는 하나의 페이지 테이블을 가지며, 페이지 테이블은 운영체제 영역에 있다. 따라서 페이지 테이블의 크기가 너무 커지면 프로세스가 실제로 사용할 수 있는 메모리 영역이 줄어든다. 사용할 수 있는 물리 메모리 영역이 적을 경우 프로세스만 스왑 영역으로 옮겨지는 것이 아니라 페이지 테이블의 일부도 스왑 영역으로 옮겨진다.

159. 직접 매핑  
직접 매핑은 모든 페이지 테이블을 물리 메모리에 가지고 있는 가장 단순한 방식이다. 물리 메모리가 충분할 때 사용할 수 있으며, 모든 페이지를 물리 메모리에 가지고 있기 때문에 주소 변환 속도가 빠르다.

160. 연관 매핑  
연관 매핑은 전체 페이지 테이블을 스왑 영역에 두고 페이지 테이블의 일부를 물리 메모리에 가져오는 방식이다. 그러므로 물리 메모리에는 일부 페이지만 무작위로 저장되어 있고 그 일부분의 테이블을 변환 색인 버퍼(Translation Look-0aside Buffer, TLB) 또는 연관 레지스터(Associate register)라고 부른다. 변환 색인 버퍼는 페이지 번호와 프레임 번호로 구성된 작은 크기의 테이블이다.

161. 연관 매핑 방식은 전체 페이지 테이블을 물리 메모리에 보관하지 않아 메모리를 절약할 수 있다는 것이 장점이다. 그러나 TLB 미스가 빈번하게 발생할 경우 시스템의 성능이 떨어지는 단점도 있다. 또한 변환 색인 버퍼는 페이지 테이블의 일부를 무작위로 가지고 있기 때문에 모든 변환 색인 버퍼를 검색한 후에야 원하는 페이지가 메모리에 없다는 것을 알 수 있다. 즉, TLB 미스를 알게 되는 시점이 변환 색인 버퍼를 모두 검색하고 난 후이다. 따라서 TLB 미스가 발생하면 주소 변환이 느려진다.

162. 집합-연관 매핑  
연관 매핑에서 모든 변환 색인 버퍼를 검색한 후에야 TLB 미스가 있다는 사실을 알게 됨으로써 전체 시스템의 성능이 떨어지는 단점을 개선한 것이 집합-연관 매핑 방식이다. 일반적으로 컴퓨터를 사용할 때 파일이 많으면 디렉터리를 사용하여 일정한 묶음으로 모아놓는다. 디렉터리 매핑(directory mapping)이라고도 하는 집합-연관 매핑은 관련 있는 테이블을 덩어리로 모아 놓은 형태이다.

163. 역매핑  
지금까지 살펴본 매핑 방식은 가상 주소의 페이지를 기준으로 프레임 번호를 매핑했다. 이러한 방식은 프로세스마다 페이지 테이블이 필요하고 그 크기도 작지 않기 때문에 물리 메모리 공간을 낭비하는 것이 문제이다. 역매핑은 이와 달리 물리 메모리의 프레임 번호를 기준으로 테이블을 작성한다. 즉 물리 메모리가 어떤 프로세스의 어떤 페이지를 가지고 있는지를 테이블 형태로 구성한다.

### 3. 세그먼테이션 기법
164. 세그먼테이션 기법은 가변 분할 방식을 기본으로 하므로 가변 분할 방식의 장점과 단점을 모두 가지고 있다. 장점으로는 메모리를 프로세스 단위로 관리하기 때문에 페이지 테이블이 작고 단순하다는 것을 꼽을 수 있고, 단점은 물리 메모리의 외부 단편화로 인해 물리 메모리 관리가 복잡하다는 것이다.

### 4. 세그먼테이션-페이징 혼용 기법
165. 페이징 기법은 물리 메모리를 같은 크기로 나누어 관리하기 때문에 메모리 관리가 수월한 반면 페이지 테이블의 크기가 크다. 또한 세그먼테이션 기법은 페이지 테이블의 크기를 작게 유지할 수 있으나 물리 메모리의 외부 단편화로 인해 추가적인 관리가 불가피하다. 세그먼테이션-페이징 혼용 기법은 이 두 기법의 장점만 취한 가상 메모리 관리 기법이다.

166. 페이징 기법에 세그먼테이션 테이블을 추가하고, 권한 비트와 같이 중복되는 데이터를 세그먼테이션 테이블로 옮겨 오면 테이블의 크기를 줄일 수 있따. 이렇게 페이징 기법과 세그먼테이션 기법을 혼합하여 사용하면 순수 페이징 기법과 순수 세그먼테이션 기법의 장점만 취함으로써 메모리 관리를 효율적으로 할 수 있는데, 이를 세그먼테이션-페이징 혼용 기법이라고 한다. 현재 대부분의 운영체제는 이 방식을 사용하고 있다.

# Chapter 9. 가상 메모리 관리
### 1. 요구 페이징
### 2. 페이지 교체 알고리즘
### 3. 스레싱과 프레임 할당
### 4. 프레임 관련 이슈


# Part4. 저장장치 관리
# Chapter 10. 입출력 시스템과 저장장치
### 1. 입출력 시스템
### 2. 디스크 장치
### 3. 디스크 스케줄링
### 4. RAID
### 5. 하드웨어의 규격과 발전

# Chapter 11. 파일 시스템
### 1. 파일과 파일 시스템
### 2. 디렉터리의 구조
### 3. 디스크 파일 할당
### 4. 유닉스 파일의 특징

# Part5. 분산 시스템
# Chapter 12. 네트워크와 분산 시스템
### 1. 네트워크와 인터넷
### 2. 분산 시스템
### 3. 분산 시스템의 고가용성

#운영체제#조성호


# 운영체제
### 지은이 : 조성호
### 출판사 : 한빛아카데미
### 읽은 날 : 2020.02.22 ~

<목차>
# Part1. 운영체제와 컴퓨터
### Chapter 1. 운영체제의 개요
1. 운영체제 소개
2. 운영체제의 역사
3. 운영체제의 구조
4. 운영체제의 종류와 역사

### Chapter 2. 컴퓨터 구조와 성능 향상
1. 컴퓨터의 기본 구성
2. CPU와 메모리
3. 컴퓨터 성능 향상 기술
- 버퍼
- 캐시
- 저장장치의 개층 구조
- 인터럽트
4. 병렬 처리
5. 무어의 법칙과 암달의 법칙


# Part2. 프로세스 관리
### Chapter 3. 프로세스와 스레드
1. 프로세스 개요
2. 프로세스 제어 블록과 문맥 교환
3. 프로세스의 연산
4. 스레드
5. 동적 할당 영역과 시스템 호출

### Chapter 4. CPU 스케줄링
1. 스케줄링의 개요
2. 스케줄링 시 고려 사항
3. 다중 큐
4. 스케줄링 알고리즘
5. 인터럽트 처리

### Chapter 5. 프로세스 동기화
1. 프로세스 간 통신
2. 공유 자원과 임계구역
3. 임계구역 해결 방법
4. 파일, 파이프, 소켓 프로그래밍

### Chapter 6. 교착 상태
1. 교착 상태의 개요
2. 교착 상태 필요조건
3. 교착 상태 해결 방법
4. 다중 자원과 교착 상태 검출


#Part3. 메모리 관리
### Chapter 7. 물리 메모리 관리
1. 메모리 관리의 개요
2. 메모리 주소
3. 단일 프로그래밍 환경에서의 메모리 할당
4. 다중 프로그래밍 환경에서의 메모리 할당
5. 컴파일과 메모리 관리

### Chapter 8. 가상 메모리 기초
1. 가상 메모리 개요
2. 페이징 기법
3. 세그먼테이션 기법
4. 세그먼테이션-페이징 혼용 기법
5. 캐시 매핑 기법

### Chapter 9. 가상 메모리 관리
1. 요구 페이징
2. 페이지 교체 알고리즘
3. 스레싱과 프레임 할당
4. 프레임 관련 이슈


# Part4. 저장장치 관리
### Chapter 10. 입출력 시스템과 저장장치
1. 입출력 시스템
2. 디스크 장치
3. 디스크 스케줄링
4. RAID
5. 하드웨어의 규격과 발전

### Chapter 11. 파일 시스템
1. 파일과 파일 시스템
2. 디렉터리의 구조
3. 디스크 파일 할당
4. 유닉스 파일의 특징

# Part5. 분산 시스템
### Chapter 12. 네트워크와 분산 시스템
1. 네트워크와 인터넷
2. 분산 시스템
3. 분산 시스템의 고가용성

-------------------------------------------
# Part1. 운영체제와 컴퓨터
# Chapter 1. 운영체제의 개요
### 1. 운영체제 소개
1. 펌웨어
운영체제는 우리가 사용하는 각종 소프트웨어 중 하나이다. 게임이나 문서 편집기 같은 소프트웨어가 특정 목적을 위해 존재한다면, 운영체제는 컴퓨터에 있는 하드웨어(자원)를 조정하고 관리하기 위해 존재한다. 그런데 운영체제는 하드웨어를 조정하고 관리하는 역할을 하므로 하드웨어의 도움 없이 작동하기가 어렵기 때문에 운영체제를 소프트웨어와 하드웨어로 결합한 형태인 펌웨어(firmware)라고 부르기도 한다.

2. 운영체제는 하드웨어 인터페이스가 자동으로 설치되게 함으로써 하드웨어의 종류에 상관없이 사용할 수 있게 해준다.

### 2. 운영체제의 역사
3. 천공카드 리더로 하나의 작업을 읽어들여 실행하고 결과를 출력한 후 다음 작업을 읽어들여 실행했다. 이러한 시스템에서는 작업에 필요한 프로그램과 데이터를 동시에 입력해야 작업이 가능하다. 지금의 프로그래밍 환경과 달리 모든 작업을 한꺼번에 처리해야 하고 프로그램 실행 중간에 사용자가 데이터를 입력하거나 수정하는 것이 불가능한데, 이러한 시스템을 일괄 작업 시스템(batch job system)또는 일괄 처리 시스템(batch processing system)이라고 부른다.

4. 이처럼 여러 작업을 조금씩 처리하여 작업이 동시에 이루어지는 것처럼 보이게 하는 것을 시분할 시스템(time sharing system)이라고 한다. 다중 작업(multitasking)시스템이라고도 불리는 시분할 시스템에서는 CPU 사용 시간을 잘게 나뉜 시간 한 조각을 타임 슬라이스(time slice)또는 타임 퀀텀(time quantum)이라고 한다. 오늘날의 컴퓨터에는 대부분 시분할 시스템이 사용된다.

### 3. 운영체제의 구조
5. 시스템 호출(system call)
시스템 호출은 커널이 자신을 보호하기 위해 만든 인터페이스이다. 커널은 사용자나 응용 프로그램으로부터 컴퓨터 자원을 보호하기 위해 자원에 직접 접근하는 것을 차단한다. 따라서 자원을 이용하려면 시스템 호출이라는 인터페이스를 이용하여 접근해야 한다.

6. 시스템 호출에 관한 내용을 정리하면 다음과 같다.
- 시스템 호출은 커널이 제공하는 시스템 자원의 사용과 연관된 함수이다.
- 응용 프로그램이 하드웨어 자원에 접근하거나 운영체제가 제공하는 서비스를 이용하려 할 때는 시스템 호출을 사용해야 한다.
- 운영체제는 커널이 제공하는 서비스를 시스템 호출로 제한하고 다른 방법으로 커널에 들어오지 못하게 막음으로써 컴퓨터 자원을 보호한다.
- 시스템 호출은 커널이 제공하는 서비스를 이용하기 위한 인터페이스이며, 사용자가 자발적으로 커널 영역에 진입할 수 있는 유일한 수단이다.

7. 시스템 호출 부분을 보면 커널 앞부분 전체를 감싸고 있는데, 이는 시스템 호출을 거치지 않고 커널에 진입할 수 없다는 의미이다. 반면에 드라이버는 커널 전체를 감싸고 있지 않다. 이는 커널이 제공하는 드라이버도 있고 하드웨어 제작자가 제공하는 드라이버도 있다는 뜻으로, 하드웨어는 커널과 직접 연결되기도 하고 하드웨어 제작자가 제공하는 드라이버를 통해 연결되기도 한다.

8. 커널이 하는 일
- 프로세스 관리 : 프로세스에 CPU를 배분하고 작업에 필요한 제반 환경을 제공한다.
- 메모리 관리 : 프로세스에 작업 공간을 배치하고 실제 메모리보다 큰 가상공간을 제공한다.
- 파일 시스템 관리 : 데이터를 저장하고 접근할 수 있는 인터페이스를 제공한다.
- 입출력 관리 : 필요한 입력과 출력 서비스를 제공한다.
- 프로세스 간 통신 관리 : 공동 작업을 위한 각 프로세스 간 통신 환경을 지원한다.

9. 이런 호환성 문제를 해결한 언어가 바로 자바이다. 자바로 프로그래밍을 하면 대부분의 운영체제에서 작동하기 때문에 코드를 수정할 필요가 없다. 자바가 작동하는 원리는 매우 간단하다. 운영체제 위에 가상머신을 만들고 그 위에서 응용 프로그램이 작동하게 하는 것이다.

10. 가상머신의 개념은 다양한 곳에서 사용된다. 예를 들어 윈도우 운영체제 환경에서 유닉스를 사용하고 싶다고 가정해보자. 이 경우 윈도우 운영체제와 유닉스 운영체제를 같이 설치하고 부팅할 때 어떤 운영체제를 사용할지 선택해야 한다. 그러나 대부분의 작업을 윈도우에서 하고 유닉스는 가끔 사용한다면 하나의 컴퓨터에 두 가지 운영체제를 설치하기가 부담스러운데, 이럴 때는 윈도우 운영체제에 유닉스 가상머신을 설치하여 사용하면 된다. 가상머신을 사용하면 호환성이 높아지지만 응용 프로그램이 가상머신을 통해서만 작동하기 때문에 느려진다는 단점도 있다.

11. 커널의 종류
- 단일형 구조 커널 : 커널의 핵심 기능을 구현하는 모듈들이 구분 없이 하나로 구성되어 있다.
- 계층형 구조 커널 : 비슷한 기능을 가진 모듈을 묶어서 하나의 계층으로 만들고 계층 간의 통신을 통해 운영체제를 구현하는 방식이다.
- 마이크로 구조 커널 : 운영체제가 프로세스 관리, 메모리 관리, 프로세스 간 통신 관리 등 가장 기본적인 기능만 제공한다.

### 4. 운영체제의 종류와 역사

# Chapter 2. 컴퓨터 구조와 성능 향상
### 1. 컴퓨터의 기본 구성
12. 폰노이만 구조에서 가장 중요한 특징은, ‘모든 프로그램은 메모리에 올라와야 실행할 수 있다’는 것이다.

13. 클록(clock)
클록은 CPU 속돵 관련된 단위이다. 다양한 악기로 조합된 오케스트라는 박자가 맞아야 제대로 곡을 연주할 수 있듯이 CPU도 작업을 할 때 일정한 박자가 있는데, 이 박자를 만들어내는 것이 클록이다. 클록이 일정한 간격으로 틱(tick)을 만들면 거기에 맞추어 CPU안의 모든 구성 부품이 작업을 한다. 틱은 펄스(pulse) 또는 클록틱(clock tick)이라고도 부른다. 버스에는 여러 개의 부품이 연결되어 있는데, 메인보드의 클록이 틱을 보낼 때마다 데이터를 보내거나 받는다.

14. 헤르츠(Hz)
헤르츠는 클록틱이 발생하는 속도를 나타내는 단위이다. 1초에 클록틱이 몇 번 발생하는지를 나타내는데, 1초에 클록틱이 한 번이면 1Hz, 1000번이면 1kHz이다.

15. 시스템 버스(system bus)와 CPU 내부 버스
시스템 버스는 메모리와 주변장치를 연결하는 버스로 FSB(Front-Side Bus), 즉 전면 버스라고 한다. 1,333MHz의 시스템 버스를 가진 메인보드에는 같은 속도를 가진 부품이 연결되고 메모리도 1,333MHz의 속도로 작동한다.

16. CPU 내부 버스는 CPU 내부에 있는 장치를 연결하는 버스로 BSB(Back-Side Bus), 즉 후면 버스라고 한다. CPU 내부 버스의 속도는 CPU 클록과 같아서 시스템 버스보다 훨씬 빠르다.

### 2. CPU와 메모리
17. CPU는 0과 1의 2진수로 이루어진 기계어(machine code)만 인식한다. 따라서 위 코드를 실행하려면 컴파일러를 이용하여 기계어로 바꾸어야 한다. 여기서는 사람이 이해하기 어려운 기계어 대신 어셈블리어로 작성한 코드를 살펴보자. 어셈블리어는 기계어를 사람이 이해하기 쉬운 기호와 일대일로 대응시켜 기호화한 언어이다.

18. 사용자 가시 레지스터
- 데이터 레지스터(DR) : CPU가 명령어를 처리하는 데 필요한 일반 데이터를 임시로 저장하는 범용 레지스터이다.
- 주소 레지스터(AR) : 데이터 또는 명령어가 저장된 메모리 주소를 저장한다.

19. 사용자 불가시 레지스터
- 프로그램 카운터(PC) : 다음에 실행할 명령어의 위치 정보(코드의 행 번호, 메모리 주소)를 저장한다.
- 명령어 레지스터(IR) : 현재 실행 중인 명령어를 저장한다.
- 메모리 주소 레지스터(MAR) : 메모리 관리자가 접근해야 할 메모리의 주소를 저장한다.
- 메모리 버퍼 레지스터(MBR) : 메모리 관리자가 메모리에서 가져온 데이터를 임시로 저장한다.
- 프로그램 상태 레지스터(PSR) : 연산 결과(양수, 음수 등)를 저장한다.

20. 제어 버스(control bus)
제어 버스에서는 다음에 어떤 작업을 할지 지시하는 제어 신호가 오고 간다. … 제어 버스의 신호는 CPU, 메모리, 주변장치와 양방향으로 오고 간다.

21. 주소 버스(address bus)
주소 버스에서는 메모리의 데이터를 읽거나 쓸 때 어느 위치에서 작업할 것인지를 알려주는 위치 정보(주소)가 오고 간다. … 주소 버스는 메모리 주소 레지스터와 연결되어 있으며 단방향이다. CPU에서 메모리나 주변장치로 나가는 주소 정보는 있지만 주소 버스를 통해 CPU로 전달되는 정보는 없다.

22. 데이터 버스(data bus)
제어 버스가 다음에 어떤 작업을 할지 신호를 보내고 주소 버스가 위치 정보를 전달하면 데이터가 데이터 버스에 실려 목적지까지 이동한다. 데이터 버슨느 메모리 버퍼 레지스터와 연결되어 있으며 양방향이다.

23. 버스의 대역폭(bandwidth)은 한 번에 전달할 수 있는 데이터의 최대 크기를 말한다. … 흔히 32bit CPU, 64bit CPU라고 하는데 여기서 32bit, 64bit는 CPU가 한 번에 처리할 수 있는 데이터의 최대 크기이다. … 참고로 CPU가 한 번에 처리할 수 있는 데이터의 최대 크기를 워드(word)라고 하며, 버스의 대역폭과 메모리에 한 번에 저장되는 단위도 워드이다. 32bit CPU에서 1워드는 32bit이다.

24. 휘발성 메모리(volatility memory)
휘발성 메모리에는 DRAM(Dynamic RAM, 동적 램)과 SRAM(Static RAM, 정적 램)이 있다. DRAM은 저장된 0과 1의 데이터가 일정 시간이 지나면 사라지므로 일정 시간마다 다시 재생시켜야 한다. DRAM의 ‘Dynamic’은 시간이 지나면 데이터가 사라지기 때문에 재생이 필요하다는 의미이다. SRAM은 전력이 공급되는 동안에는 데이터를 보관할 수 있어 재생할 필요가 없다. 따라서 속도는 빠르지만 가격이 비싸다. 일반적으로 메인메모리에는 DRAM을 사용하고, 캐시 같은 고속 메모리에는 SRAM을 사용한다.

25. 위 그림에서 B 작업의 메모리 시작 주소 140은 경계 레지스터에, B 작업의 크기 40은 한계 레지스터에 저장된다. B 작업이 데이터를 읽거나 쓸 때마다 CPU는 해당 작업이 경계 레지스터와 한계레지스터의 주소값 안에서 이루어지는지 검사한다. 만약 두 레지스터의 값을 벗어난다면 메모리 오류와 관련된 인터럽트가 발생한다. 인터럽트가 발생하면 모든 작업이 중단되고 CPU는 운영체제를 깨워서 인터럽트를 처리하도록 시킨다. 이처럼 모든 메모리 영역은 하드웨어와 운영체제의 협업에 의해 보호받는다.

26. 부팅(booting)
컴퓨터를 켰을 때 운영체제를 메모리에 올리는 과정을 부팅이라고 한다.

27. 부트스트랩 코드는 운영체제를 메모리로 가져와 실행하는 역할을 하는 작은 프로그램이다.

### 3. 컴퓨터 성능 향상 기술
28. 현대 컴퓨터 구조의 가장 큰 문제는 CPU와 메모리, 주변장치의 작업 속도가 다르다는 것이다. 앞에서 살펴보았듯이 메인보드 내 메모리와 주변장치는 시스템 버스(FSB)로 연결되어 있고, CPU 내 레지스터, 산술논리 연산장치, 제어장치는 CPU 내부 버스(BSB)로 연결되어 있다. 따라서 메모리의 속도는 시스템 버스의 속도와 같고 CPU의 속도는 CPU 내부 버스의 속도와 같은데, CPU 내부 버스의 속도가 시스템 버스의 속도보다 빠르기 때문에 메모리를 비롯한 주변장치의 속도가 CPU의 속도를 따라가지 못한다. CPU에 비하면 메모리가 느린 것은 물론이고, 프로그램과 데이터를 보관하는 하드디스크의 속도는 더욱 느리다.

29. 버퍼(buffer)
버퍼는 속도에 차이가 있는 두 장치 사이에서 그 차이를 완화하는 역할을 한다. … 일정량의 데이터를 모아 옮김으로써 속도 차이를 완화하는 장치가 버퍼이다.

30. 하드디스크에는 메모리 버퍼가 있다. 표2-2의 하드디스크 사양은 1TB, 7200rpm, 32MB인데, 이는 하드디스크의 용량이 1TB, 디스크의 회전 속도가 7500rpm, 버퍼의 용량이 32MB라는 의미이다. 같은 사양의 하드디스크라면 버퍼의 용량이 큰 것이 더 빠르다.

31. 스풀러는 일종의 버퍼이지만 기존의 버퍼와 다른 점이 있다. 버퍼의 경우 어떤 프로그램이 사용하는 데이터든 버퍼가 차면 이동이 시작된다. 다시 말해 프로그램들이 버퍼를 공유한다. 반면에 스풀러는 한 인쇄물이 완료될 때까지 다른 인쇄물이 끼어들 수 없으므로 프로그램 간에 배타적이다.

32. 캐시(cache)
캐시는 메모리와 CPU 간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해두는 임시 장소이다. 캐시는 필요한 데이터를 모아 한꺼번에 전달하는 버퍼의 일종으로 CPU가 앞으로 사용할 것으로 예상되는 데이터를 미리 가져다놓는다. 이렇게 미리 가져오는 작업을 ‘미리 가져오기(prefetch)’라고 한다.

33. 캐시는 CPU 안에 있으며 CPU 내부 버스의 속도로 작동한다. 메모리의 경우 시스템 버스의 속도로 작동하기 때문에 느리다. 캐시는 빠른 속도로 작동하는 CPU와 느린 속도로 작동하는 메모리 사이에서 두 장치의 속도 차이를 완화해준다.

34. 캐시는 메모리의 내용 중 일부를 미리 가져오고, CPU는 메모리에 접근해야 할 때 캐시를 먼저 방문하여 원하는 데이터가 있는지 찾아본다. 캐시에서 원하는 데이터를 찾았다면 캐시 히트(cache hit)라고 하며, 그 데이터를 바로 사용한다. 그러나 원하는 데이터가 캐시에 없으면 메모리로 가서 데이터를 찾는데 이를 캐시 미스(cache miss)라고 한다. 캐시 히트가 되는 비율을 캐시 적중률(cache hit ratio)이라고 하며, 일반적인 컴퓨터의 캐시 적중률은 약 90%이다.

35. 컴퓨터의 성능을 향상하려면 캐시 적중률이 높아야 한다. 캐시 적중률을 높이는 방법 중 하나는 캐시의 크기를 늘리는 것이다. 캐시의 크기가 커지면 더 많은 데이터를 미리 가져올 수 있어 캐시 적중률이 올라간다. 클록이 같은 CPU라도 저가형과 고가형은 캐시의 크기가 다르다.

36. 즉시 쓰기와 지연 쓰기
캐시에 있는 데이터가 변경되는 경우 이를 반영해야 하는 문제도 있다. 캐시는 메모리에 있는 데이터를 임시로 가져온 것이기 때문에 캐시에 있는 데이터가 변경되면 메모리에 있는 원래 데이터를 변경해야 한다. 캐시의 변경된 데이터를 메모리에 반영하는 데에는 즉시 쓰기 방식과 지연 쓰기 방식이 있다.

37. 웹 브라우저 캐시
캐시는 소프트웨어적으로도 사용되는데 대표적인 예가 웹 브라우저 캐시이다. 웹에서 사용하는 캐시는 ‘앞으로 다시 방문할 것을 예상하여 지우지 않는 데이터’라고 정의할 수 있다. 다음이나 네이버와 같이 자주 방문하는 사이트의 경우 로고나 버튼 등의 작은 그림이 자주 바뀌지 않는데, 로고나 버튼 등의 데이터를 캐시에 보관하고 있다가 사이트를 다시 방문하면 캐시에 있는 데이터를 사용하여 속도를 높인다. 이처럼 웹 브라우저의 캐시는 방문했던 사이트의 데이터를 보관하여 재방문 시 속도를 높이는 역할을 한다. 그러나 너무 많은 데이터가 캐시에 보관되어 있으면 웹 브라우저의 속도를 떨어뜨릴 수 있으므로 가끔 청소를 하는 것이 좋다.

38. 인터럽트
입출력 관리자가 CPU에 보내는 완료 신호를 인터럽트라고 한다. CPU는 입출력 관리자에게 작업 지시를 내리고 다른 일을 하다가 완료 신호를 받으면 하던 일을 중단하고 옮겨진 데이터를 처리한다. 이처럼 하던 작업을 중단하고 처리해야 하는 신호라는 의미에서 인터럽트라고 불리게 되었다.

39. 직접 메모리 접근(DMA, Direct Memory Access)
입출력이 필요할 때 CPU는 입출력 관리자에게 입출력 요청을 보내고 자신은 하던 일을 계속한다. 명령을 받은 입출력 관리자는 CPU가 요청한 데이터를 메모리에 가져다 놓아야 하는데 이때 문제가 있다. 메모리는 CPU만 접근 권한을 가진 작업 공간이라 입출력 관리자는 접근이 불가하다는 것이다. 따라서 입출력 관리자에게는 CPU의 허락 없이 메모리에 접근할 수 있는 권한이 필요한데, 이러한 권한을 직접 메모리 접근이라고 한다.

### 4. 병렬 처리
40. 병렬 처리에서 작업을 N개로 쪼갰을 때 N을 병렬 처리의 깊이(depth of parallel processing)라고 한다.

41. 병렬 처리의 깊이 N은 동시에 처리할 수 있는 작업의 개수를 의미한다.

42. 이론적으로는 N이 커질수록 동시에 작업할 수 있는 작업의 개수가 많아져서 성능이 높아질 것이다. 하지만 작업을 너무 많이 나누면 각 단계마다 작업을 이동하고 새로운 작업을 불러오는 데 시간이 너무 많이 걸려서 오히려 성능이 떨어진다. 이러한 오버헤드를 고려하여 보통 병렬 처리의 깊이를 10~20정도로 한다.

43.병렬 처리 기법
CPU 내에서 명령어는 제어장치가 처리한다. 제어장치는 명령어를 가져와 해석한 후 실행하고 결과를 저장하는 과정을 계속 반복한다. 이러한 과정 전체를 하나의 스레드라고 하며, 스레드를 이루는 각 단계는 CPU의 클록과 연동되어 한 클록에 한 번씩 이루어진다.

44. CPU는 이러한 단계를 계속 반복하면서 명령어를 처리한다.
1) 명령어 패치(Instruction Fetch, IF) : 다음에 실행할 명령어를 명령어 레지스터에 저장한다.
2) 명령어 해석(instruction Decode, ID) : 명령어를 해석한다.
3) 실행(Execution, EX) : 해석한 결과를 토대로 명령어를 실행한다.
4) 쓰기(Write Back, WB) : 실행된 결과를 메모리에 저장한다.

45. 병렬 처리 기법은 하나의 코어에서 작업을 나누어 병렬로 처리하는 파이프라인 기법과 여러 개의 코어를 사용하여 동시에 작업을 진행하는 슈퍼스칼라 기법으로 나뉜다.

46. 파이프라인(pipeline) 기법
파이프라인 기법은 CPU의 사용을 극대화하기 위해 명령을 겹쳐서 실행하는 방법으로, CPU의 사양과 연관지어 보면 하나의 코어에 여러 개의 스레드를 사용하는 것이다.

### 5. 무어의 법칙과 암달의 법칙
47. 인텔의 공동 창업자인 고든 무어(Gordon Moore)는 CPU의 속도가 24개월마다 2배 빨라진다는 무어의 법칙을 주장했다. 그러나 이 주장은 초기의 CPU에만 적용되며 지금은 그렇지 않다. CPU는 자체 발열 문제로 속도를 5GHz 이상 높이기 어렵기 때문에 요즘에는 처리 속도를 올리는 대신 멀티코어를 장착하는 방향으로 나아가고 있다.

48. 멀티코어와 함께 멀티스레드도 많이 사용되고 있다. 멀티스레드는 하나의 코어에서 여러 개의 명령어를 실행하는 기술이다.

49. 암달의 법칙(Amdahl’s law)
진 암달(Gene Amdahl)은 컴퓨터 시스템의 일부를 개선할 때 전체 시스템에 미치는 영향과의 관계를 수식으로 나타낸 암달의 법칙을 만들었다. 이 법칙에 따르면 주변장치의 향상 없이 CPU의 속도를 2GHz에서 4GHz로 늘리더라도 컴퓨터의 성능이 2배 빨라지지 않는다. 앞에서도 설명했듯이 CPU의 속도를 올린다고 해도 메모리를 비롯한 주변장치가 CPU의 발전 속도를 따라가지 못해 컴퓨터의 전반적인 성능이 저하되는 것이다. 암달의 법칙은 멀티코어에도 적용되는데, 코어가 하나인 싱글코어 대신 듀얼코어를 사용하더라도 CPU 내 다른 부품의 병목 현상으로 인해 CPU의 성능이 2배가 되지 않는다.

# Part2. 프로세스 관리
# Chapter 3. 프로세스와 스레드
### 1. 프로세스 개요
### 2. 프로세스 제어 블록과 문맥 교환
### 3. 프로세스의 연산
### 4. 스레드
### 5. 동적 할당 영역과 시스템 호출

# Chapter 4. CPU 스케줄링
### 1. 스케줄링의 개요
### 2. 스케줄링 시 고려 사항
### 3. 다중 큐
### 4. 스케줄링 알고리즘
### 5. 인터럽트 처리

# Chapter 5. 프로세스 동기화
### 1. 프로세스 간 통신
### 2. 공유 자원과 임계구역
### 3. 임계구역 해결 방법
### 4. 파일, 파이프, 소켓 프로그래밍

# Chapter 6. 교착 상태
### 1. 교착 상태의 개요
### 2. 교착 상태 필요조건
### 3. 교착 상태 해결 방법
### 4. 다중 자원과 교착 상태 검출


# Part3. 메모리 관리
# Chapter 7. 물리 메모리 관리
### 1. 메모리 관리의 개요
### 2. 메모리 주소
### 3. 단일 프로그래밍 환경에서의 메모리 할당
### 4. 다중 프로그래밍 환경에서의 메모리 할당
### 5. 컴파일과 메모리 관리

# Chapter 8. 가상 메모리 기초
### 1. 가상 메모리 개요
### 2. 페이징 기법
### 3. 세그먼테이션 기법
### 4. 세그먼테이션-페이징 혼용 기법
### 5. 캐시 매핑 기법

# Chapter 9. 가상 메모리 관리
### 1. 요구 페이징
### 2. 페이지 교체 알고리즘
### 3. 스레싱과 프레임 할당
### 4. 프레임 관련 이슈


# Part4. 저장장치 관리
# Chapter 10. 입출력 시스템과 저장장치
### 1. 입출력 시스템
### 2. 디스크 장치
### 3. 디스크 스케줄링
### 4. RAID
### 5. 하드웨어의 규격과 발전

# Chapter 11. 파일 시스템
### 1. 파일과 파일 시스템
### 2. 디렉터리의 구조
### 3. 디스크 파일 할당
### 4. 유닉스 파일의 특징

# Part5. 분산 시스템
# Chapter 12. 네트워크와 분산 시스템
### 1. 네트워크와 인터넷
### 2. 분산 시스템
### 3. 분산 시스템의 고가용성

#운영체제#조성호

